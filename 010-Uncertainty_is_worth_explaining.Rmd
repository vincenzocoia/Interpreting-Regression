# An outcome on its own {-}

How can we get a handle on an outcome that seems random? Although the score of a Canucks game, a stock price, or river flow is uncertain, this does not mean that these quantities are futile to predict or describe. This part of the book describes how to do just that, using only observations on a single outcome, by shedding light on concepts of probability and univariate analysis as they apply to data science. 

# Distributions: Uncertainty is worth explaining

```{r, warning = FALSE, echo = FALSE}
suppressPackageStartupMessages(library(tidyverse))
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, fig.align = "center")
here::here("supplementary", "expense.R") %>% source()
here::here("supplementary", "octane.R") %>% source()
here::here("supplementary", "ships.R") %>% source()
```

Concepts:

- Variable types. Numeric variables vs. categorical. Ordinal as being "in between" numeric and categorical. Discrete as a special case of numeric, sometimes worth distinguishing.
- Distributions as the limiting collection of iid data. 
- Ways to depict a distribution, and the interpretation of each. The concept that one tells you everything about the distribution, so you can in theory derive one form from another. One does not give you more information than another. 
- These distributions might not seem practical, but they certainly are. Even in cases where we are considering many other pieces of information aside from the response, we are still dealing with univariate distributions -- we'll see later that the only difference is that they are no longer marginal distributions (they are _conditional_).


## Defining Probability

I like to play Mario Kart 8, a racing game with some "combat" involved using items. In the game, you are given an item at random whenever you get an "item box".

Suppose you're playing the game, and so far have gotten the following items in total:

|Item                                  | Name    | Count|
|:------------------------------------:|:-------:|:----:|
|<img src='./img/banana.png'> | Banana  |     7|
|<img src='./img/bobomb.png'> | Bob-omb |     3|
|<img src='./img/coin.png'>   | Coin    |    37|
|<img src='./img/horn.png'>   | Horn    |     1|
|<img src='./img/shell.png'>  | Shell   |     2|
| Total: | | 50 |

Attribution: images from [pngkey](https://www.pngkey.com/detail/u2w7e6o0i1q8i1y3_randome-clipart-mario-kart-mario-kart-8-deluxe/).


- What's the probability that your next item is a coin? 
- How would you find the _actual_ probability? 
- From this, how might you define probability?

In general, the probability of an event $A$ occurring is denoted $P(A)$ and is defined as $$\frac{\text{Number of times event } A \text{ is observed}}{\text{Total number of events observed}}$$ as the number of events goes to infinity.

## Comparing Probabilities

Suppose Vincenzo often wins at a game of solitaire---a one-player game---but that Tom is twice as good as Vincenzo. Does this means that $P(\text{Tom wins}) = 2 \times P(\text{Vincenzo wins})$?

Probability is quite useful for communicating the chance of an event happening in an absolute sense, but is not useful for comparing probabilities. Odds, on the other hand, are useful for comparing the chance of two events. If $p$ is the chance that Vincenzo wins at solitaire, his _odds of winning_ is defined as $$\text{Odds} = \frac{p}{1-p}.$$ This means that, if his odds are $o$, then the probability of winning is $$\text{Probability} = \frac{o}{o+1}.$$

For example, if Vincenzo wins 80% of the time, his odds are $0.8/0.2 = 4$. This is sometimes written as 4:1 odds -- that is, _four wins for every loss_. If Tom is twice as good as Vincenzo, it's _most useful_ to say that this means Tom wins twice as many games before experiencing a loss (on average) -- that is, 8:1 odds, or simply 8, and a probability of $8/9=0.888\ldots$.


## Probability Distributions

So far, we've been discussing probabilities of single events. But it's often useful to characterize the full "spectrum" of uncertainty associated with an outcome. The set of all outcomes and their corresponding probabilities is called a __probability distribution__ (or, often, just __distribution__). 

The outcome itself, which is uncertain, is called a __random variable__. (Note: technically, this definition only holds if the outcome is _numeric_, not categorical like our Mario Kart example, but we won't concern ourselves with such details)

When the outcomes are _discrete_, the distributions are called __probability mass functions__ (or _pmf_'s for short).

### Examples of Probability Distributions (3 min)

__Mario Kart Example__: The distribution of items is given by the above table.

__Ship example__: Suppose a ship that arrives at the port of Vancouver will stay at port according to the following distribution:

| Length of stay (days) | Probability |
|---|------|
| 1 | 0.25 |
| 2 | 0.50 |
| 3 | 0.15 |
| 4 | 0.10 |

The fact that the outcome is _numeric_ means that there are more ways we can talk about things, as we will see.

## Continuous random variables (10 min)

What is the current water level of the Bow River at Banff, Alberta? How tall is a tree? What about the current atmospheric temperature in Vancouver, BC? These are examples of _continuous_ random variables, because there are an _uncountably infinite_ amount of outcomes. Discrete random variables, on the other hand, are _countable_, even if there are infinitely many outcomes, because each outcome can be accounted for one-at-a-time by some pattern. 

__Example__: The positive integers are discrete/countable: just start with 1 and keep adding 1 to get 1, 2, 3, etc., and that covers all possible outcomes. Positive real numbers are not countable because there's no way to cover all possibilities by considering one outcome at a time. 

It turns out that it's trickier to interpret probabilities for continuous random variables, but it also turns out that they're in general easier to work with. 

Not all random variables with infinitely many outcomes are continuous. Take, for example, a Poisson random variable, that can take values $0, 1, 2, \ldots$ with no upper limit. The difference here is that a smaller range of values _does_ have a finite amount of variables. By the way, this type of infinity is called "countably infinite", and a continuous random variable has "uncountably infinite" amount of outcomes.

In practice, we can never measure anything on a continuous scale, since any measuring instrument must always round to some precision. For example, your kitchen scale might only measure things to the nearest gram. But, these variables are well approximated by a continuous variable. As a rule of thumb, if the difference between neighbouring values isn't a big deal, consider the variable continuous. 

__Example__:

You'd like to get a handle on your monthly finances, so you record your total monthly expenses each month. You end up with `r length(expense$sample)` months worth of data:

```{r, results = "as.is"}
expense$sample %>% 
  str_c("$", .)
```

Since a difference of $0.01 isn't a big deal, we may as well treat this as a continuous random variable. 

__Example__:

Back in the day when Canada had pennies, you liked to play "penny bingo", and wrote down your winnings after each day of playing the game with your friends. Here are your net winnings:

```{r}
set.seed(4)
(rnorm(10, mean = 0, sd = 2.5)/100) %>% 
  round(2)
```

Since a difference of $0.01 is a big deal, best to treat this as discrete. 


## Density Functions (20 min)

In the discrete case, we were able to specify a distribution by indicating a probability for each outcome. Even when there's an infinite amount of outcomes, such as in the case of a Poisson distribution, we can still place a non-zero probability on each outcome and have the probabilities sum to 1 (thanks to [convergent series](https://en.wikipedia.org/wiki/Convergent_series)). But an uncountable amount of outcomes cannot be all accounted for by a sum (i.e., the type of sum we denote by $\sum$), and this means that _continuous outcomes must have probability 0_. 

__Example__: The probability that the temperature in Vancouver tomorrow will be 18 degrees celcius is 0. In fact, any temperature has a probability of 0 of occurring. 

While individual outcomes have zero probability, _ranges_ can have non-zero probability. We can use this idea to figure out how "dense" the probability is at some areas of the outcome space. For example, if a randomly selected tree has a 0.05 probability of being within 0.1m of 5.0m, then as a rate, that's about 0.05/(0.1m) = 0.5 "probability per meter" here. Taking the limit as the range width $\rightarrow 0$, we obtain what's called the __density__ at 5m. 

The density as a function over the outcome space is called the __probability density function__ (pdf), usually abbreviated to just the __density__, and denoted $f$. Sometimes we specify the random variable in the subscript, just to be clear about what random variable this density represents -- for example, $f_X$ is the density of random variable $X$.

You'll see that the density is like a "continuous cousin" of the _probability mass function_ (pmf) in the case of discrete random variables. We'll also see in a future lecture that there are some random variables for which neither a density nor a pmf exist.

 We can use the density to calculate probabilies of a range by integrating the density over that range: $$P(a < X < b) = \int_a^b f(x) \text{d}x.$$ This means that, integrating over the entire range of possibilities should give us 1:
 $$\int_{-\infty}^\infty f(x) \text{d}x = 1$$
This integral corresponds to the entire area under the density function.


### Example: "Low Purity Octane"

You just ran out of gas, but luckily, right in front of a gas station! Or maybe not so lucky, since the gas station is called "Low Purity Octane". They tell you that the octane purity of their gasoline is random, and has the following density:

```{r, fig.width = 3, fig.height = 2}
octane$plot_ddist
```

1. What's the probability of getting 25% purity? That is, $P(\text{Purity} = 0.25)$?
2. The density evaluates to be >1 in some places. Does this mean that this is not a valid density? Why is the density in fact valid?
3. Is it possible for the density to be negative? Why or why not?
4. What's the probability of getting gas that's $<50\%$ pure? That is, $P(\text{Purity} < 0.5)$?
5. What's the probability of getting gas that's $\leq 50\%$ pure? That is, $P(\text{Purity} \leq 0.5)$?
6. What's the _support_ of this random variable? That is, the set of all outcomes that have non-zero density?
7. You decide to spend the day at Low Purity Octane, measuring the octane purity for each customer. You end up getting `r octane$n` observations, placing each measurement along the x-axis. Which of the following plots would be more likely, and why?

```{r, fig.width = 8, fig.height = 2.2}
octane$plot_ddist + 
  facet_wrap(~ scenario, nrow = 1) +
  geom_jitter(aes(x = measurement, y = 0), 
              alpha = 0.25, 
              height = 0.05)
```

### Example: Monthly Expenses

It turns out your monthly expenses have the following density, with your 20 observations plotted below it:

```{r, fig.width = 5, fig.height = 2}
expense$plot_ddist +
  geom_jitter(
    data    = tibble(x = expense$sample),
    mapping = aes(x, y = 0), 
    height  = 1e-5, 
    alpha   = 0.5
  )
```



## Measures of central tendency and uncertainty

There are two concepts when communicating an uncertain outcome:

- __Central tendency__: a "typical" value of the outcome.
- __Uncertainty__: how "random" the outcome is.

There are many ways to _measure_ these two concepts. They're defined using a probability distribution, but just as probability can be defined as the limit of a fraction based on a sample, these measures often have a _sample version_ (aka _empirical version_) from which they are derived. 

As such, let's call $X$ the random outcome, and $X_1, \ldots, X_n$ a set of $n$ _observations_ that form a _sample_ (see the [terminology page](https://ubc-mds.github.io/resources_pages/terminology/#sample) for alternative uses of the word _sample_).

### Mode and Entropy

No matter what scale a distribution has, we can always calculate the mode and entropy. And, when the outcome is categorical (like the Mario Kart example), we are pretty much stuck with these as our choices.

The __mode__ of a distribution is the outcome having highest probability.

- A measure of central tendency.
- The sample version is the observation you saw the most.
- Measured as an _outcome_, not as the probabilities.

The __entropy__ of a distribution is defined as $$-\displaystyle \sum_x P(X=x)\log(P(X=x)).$$

- A measure of uncertainty.
- Probably the only measure that didn't originate from a sample version (comes from information theory).
- Measured as a transformation of probabilities, not as the outcomes -- so, hard to interpret on its own.
- Cannot be negative; zero-entropy means no randomness.

### Mean and Variance

When our outcome is numeric, we can take advantage of the numeric property and calculate the _mean_ and _variance_: 

The __mean__ (aka expected value, or expectation) is defined as $$\displaystyle \sum_x x\cdot P(X=x).$$

- A measure of central tendency, denoted $E(X)$.
- Its sample version is $\bar{X} = \frac{1}{n} \sum_{i=1}^n X_i,$ which gets closer and closer to the true mean as $n \rightarrow \infty$ (this is in fact how the mean is originally defined!)
- Useful if you're wanting to compare _totals_ of a bunch of observations (just multiply the mean by the number of observations to get a sense of the total).
- Probably the most popular measure of central tendency.
- Note that the mean might not be a possible outcome!

The __variance__ is defined as $$E[(X-E(X))^2],$$ or this works out to be equivalent to the (sometimes) more useful form, $$E[X^2]-E[X]^2.$$

- A measure of uncertainty, denoted $\text{Var}(X)$.
- Yes! This is an expectation -- of the squared deviation from the mean.
- Its sample version is $s^2 = \frac{1}{n-1} \sum_{i=1}^n (X_i - \bar{X})^2$, or sometimes $s^2 = \frac{1}{n} \sum_{i=1}^n (X_i - \bar{X})^2$ -- both get closer and closer to the true variance as $n \rightarrow \infty$ (you'll be able to compare the goodness of these at estimating the true variance in DSCI 552 next block). 
- Like entropy, cannot be negative, and a zero variance means no randomness.  
- Unlike entropy, depends on the actual values of the random variable.

The __standard deviation__ is the square root of the variance.

- Useful because it's measured on the same scale as the outcome, as opposed to variance, which takes on squared outcome measurements.


Note: you may have heard of the __median__ -- we'll hold off on this until later.


## Depicting Distributions (25 min)

So far, we've been saying that a pmf or a pdf is a distribution. Actually, there are more ways we can depict a distribution aside from the pmf/pdf. This section takes a deeper dive into alternative ways a probability distribution can be depicted, and their usefulness. Keep in mind that all of these depictions capture _everything_ about a distribution, which means that if one of them is given, then the other ones can be derived.

__A note on depictions of multivariate distributions__: There _is_ such thing as a multivariate cdf. It comes in handy in copula theory, which is an optional question in a lab assignment. But otherwise, it's not as useful as a multivariate _density_, so we won't cover it. And, there's no such thing as a multivariate quantile function.

### Cumulative Density Functions (cdf's) / Distribution Functions

The __cdf__ is usually denoted by $F$, and is defined as $$F(x) = P(X \leq x).$$ We can calculate this using a density $f$ by $$F(x) = \int_{-\infty}^x f(t) \, \text{d}t.$$

Unlike the pdf/pmf, the cdf always exists for any random variable. It just doesn't exist for categorical variables, because there's no such thing as "less than" or "greater than". For discrete random variables, the cdf is still a continuous function, but has a jump-discontinuity at the discrete values. 

Here are the cdf's of the octane purity, monthly expenses, and length of stay (from last time):

```{r, fig.width = 8, fig.height = 2}
cowplot::plot_grid(
  tibble(x = expense$qdist(c(0, 0.99))) %>% 
    ggplot(aes(x)) +
    stat_function(fun = expense$pdist) +
    theme_bw() +
    ylab("cdf") +
    scale_x_continuous("Monthly Expense", labels = scales::dollar_format()), 
  tibble(x = c(-0.5, 1.5)) %>% 
    ggplot(aes(x)) +
    stat_function(fun = octane$pdist) +
    theme_bw() +
    labs(x = "Octane Purity",
         y = "cdf"),
  ggplot(los$pmf) +
		geom_segment(aes(x = left, y = lag(cdf), xend = right, yend = lag(cdf))) +
		geom_point(data    = filter(los$pmf, left != -Inf, ndays != 6),
				   mapping = aes(x = right, y = cdf)) +
		geom_point(data    = filter(los$pmf, ndays != 6), 
				   mapping = aes(x = right, y = lag(cdf)), shape = 1) +
		scale_y_continuous("cdf", limits = c(0, 1)) +
		scale_x_continuous("Length of Stay (days)", limits = c(0, 6), breaks = 0:6) +
		theme_bw(),
  nrow = 1
)
```

For the discrete cdf, a hollow point is a limiting point -- the cdf does not evaluate to that point. Note that usually jump discontinuities in a cdf are connected with a straight vertical line, which we will do from now on after this plot.

In order for a function $F$ to be a valid cdf, the function needs to satisfy the following requirements:

1. Must never decrease.
2. It must never evalute to be <0 or >1.
3. $F(x) \rightarrow 0$ as $x \rightarrow -\infty$
4. $F(x) \rightarrow 1$ as $x \rightarrow \infty$.

The _empirical cdf_ (ecdf) for a sample of size $n$ treats the sample as if they are discrete values, each with probability $1/n$. Like the cdf of a discrete random variable, the ecdf is also a "step function". Here is the empirical cdf for the sample of 20 monthly expenses:

```{r, fig.width = 4, fig.height = 2}
ecdf_expense <- ecdf(expense$sample)
tibble(x = range(expense$sample) + c(-1, 1)) %>% 
  ggplot(aes(x)) +
  stat_function(fun = ecdf_expense, n = 1000) +
  theme_bw() +
  labs(x = "Monthly Expense",
       y = "Empirical cdf")
```

#### Exercise (10 min)

On the board, let's calculate the cdf's of the following two distributions (that you've seen in lab):
$$X \sim \text{Discrete Uniform}(0, 4)$$
$$Y \sim \text{Continuous Uniform}(0, 4)$$


#### Evaluating Properties using the cdf (5 min)

It turns out that the mean can be calculated in a fairly simple way from the cdf. It's the area above the cdf and to the right of $x = 0$, _minus_ the area below the cdf and to the left of $x = 0$.

In-class exercise: the cdf of octane purity is 
$$
F_{\text{Purity}}(x) = 
\begin{cases}
  0, \: x < 0\\
  x^2, \: 0 \leq x \leq 1, \\
  1, \: x > 1.
\end{cases}
$$

1. What is $P(0.5 < \text{Octane} < 0.75)$?
2. What is $P(0.5 < \text{Octane} \leq 0.75)$?
3. What is $P(\text{Octane} > 0.75)$?
4. What is the median? 0.25-quantile?
5. True or False: knowing the density of a distribution means that we also know the cdf; but knowing the cdf does not imply knowing the density.

### Survival Function (2 min)

The __survival function__ $S$ is just the cdf "flipped upside down". For random variable $X$, the survival function is defined as
$$S(x) = P(X > x) = 1 - F(x).$$

The name comes from Survival Analysis (covered in DSCI 562), where $X$ is interpreted as a "time of death", so that the survival function is the probability of surviving beyond $x$. Aside from Survival Analysis, the survival function is also useful for Extreme Value Theory.

Here are the survival functions of our three examples:

```{r, fig.width = 8, fig.height = 2}
sf_layers <- list(
	ylab("Survival Function"),
	theme_bw()
)
cowplot::plot_grid(
	tibble(x = expense$qdist(c(0, 0.99))) %>% 
		ggplot(aes(x)) +
		stat_function(fun = function(x) 1 - expense$pdist(x)) +
		scale_x_continuous("Monthly Expense", labels = scales::dollar_format()) +
		sf_layers,
	tibble(x = c(-0.5, 1.5)) %>% 
		ggplot(aes(x)) +
		stat_function(fun = function(x) 1 - octane$pdist(x)) +
		sf_layers +
		xlab("Octane Purity"),
	ggplot(los$pmf) +
		geom_segment(aes(x = left, y = 1 - lag(cdf), xend = right, yend = 1 - lag(cdf))) +
		geom_point(data    = filter(los$pmf, left != -Inf, ndays != 6),
				   mapping = aes(x = right, y = 1 - cdf)) +
		geom_point(data    = filter(los$pmf, ndays != 6), 
				   mapping = aes(x = right, y = 1 - lag(cdf)), shape = 1) +
		scale_y_continuous("Survival Function", limits = c(0, 1)) +
		scale_x_continuous("Length of Stay (days)", limits = c(0, 6), breaks = 0:6) +
		theme_bw(),
	nrow = 1
)
```



### Quantile Function (5 min)

The __quantile function__ $Q$ takes a probability $p$ and maps it to the $p$-quantile. It turns out that this is the inverse of the cdf!
$$Q(p) = F^{-1}(p)$$

Note that this function does not exist outside of $0 \leq p \leq 1$! This is unlike the other functions (density, cdf, and survival function), which exist on all real numbers. 

Here are the quantile functions of the examples we are working with:

```{r, fig.width = 8, fig.height = 2}
cowplot::plot_grid(
	tibble(x = 0:1) %>% 
		ggplot(aes(x)) +
		stat_function(fun = expense$qdist) +
		xlab("Quantile Probability") +
		scale_y_continuous("Monthly Expense", labels = scales::dollar_format()) +
		theme_bw(),
	tibble(x = 0:1) %>% 
		ggplot(aes(x)) +
		stat_function(fun = octane$qdist) +
		xlab("Quantile Probability") +
		ylab("Octane Purity") +
		theme_bw(),
	los$pmf %>% 
		pivot_longer(cols = right:left, names_to = "position", values_to = "ndays_double") %>% 
		ggplot(aes(ndays_double + 1, cdf)) +
		geom_line() + 
		coord_flip() +
		ylab("Quantile Probability") +
		scale_x_continuous("Length of Stay", limits = c(0, 6), breaks = 0:6) +
		theme_bw(),
	nrow = 1
)
```


### Other ways of depicting a distribution (Optional) (1 min)

There are even more ways to depict a distribution that we won't be going into, that you might have heard of. Denote $X$ as a random variable. Some are:

- Moment generating function (useful in mathematical statistics): $$M(t) = E(e^{Xt})$$
- Characteristic function (useful in mathematical statistics): $$\chi(t) = E(e^{Xti}),$$ where $i^2=1$.
- Hazard function (useful in survival analysis; wait for DSCI 562): $$h(t) = \frac{f(t)}{S(t)}$$



