<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 22 From Linear Regression to Mixed Effects Models | Interpreting Regression</title>
  <meta name="description" content="My tutorials for regression analysis, in the form of a bookdown book.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 22 From Linear Regression to Mixed Effects Models | Interpreting Regression" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="My tutorials for regression analysis, in the form of a bookdown book." />
  <meta name="github-repo" content="vincenzocoia/Interpreting-Regression" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 22 From Linear Regression to Mixed Effects Models | Interpreting Regression" />
  
  <meta name="twitter:description" content="My tutorials for regression analysis, in the form of a bookdown book." />
  

<meta name="author" content="Vincenzo Coia">


<meta name="date" content="2019-02-16">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="robust-regression-in-r.html">
<link rel="next" href="mixed-effects-models-in-r-tutorial.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpreting Regression</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preamble</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#caution"><i class="fa fa-check"></i><b>1.1</b> Caution</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#tasks-that-motivate-regression"><i class="fa fa-check"></i><b>1.2</b> Tasks that motivate Regression</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>2</b> Distributions</a><ul>
<li class="chapter" data-level="2.1" data-path="distributions.html"><a href="distributions.html#probabilistic-quantities"><i class="fa fa-check"></i><b>2.1</b> Probabilistic Quantities</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>3</b> Estimation</a><ul>
<li class="chapter" data-level="3.1" data-path="estimation.html"><a href="estimation.html#estimation-of-probabilistic-quantities"><i class="fa fa-check"></i><b>3.1</b> Estimation of Probabilistic Quantities</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="writing-the-sample-mean-as-an-optimization-problem.html"><a href="writing-the-sample-mean-as-an-optimization-problem.html"><i class="fa fa-check"></i><b>4</b> Writing the sample mean as an optimization problem</a></li>
<li class="chapter" data-level="5" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html"><i class="fa fa-check"></i><b>5</b> Probabilistic Forecasting</a><ul>
<li class="chapter" data-level="5.1" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#probabilistic-forecasting-what-it-is"><i class="fa fa-check"></i><b>5.1</b> Probabilistic Forecasting: What it is</a></li>
<li class="chapter" data-level="5.2" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#review-univariate-distribution-estimates"><i class="fa fa-check"></i><b>5.2</b> Review: Univariate distribution estimates</a><ul>
<li class="chapter" data-level="5.2.1" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#continuous-response"><i class="fa fa-check"></i><b>5.2.1</b> Continuous response</a></li>
<li class="chapter" data-level="5.2.2" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#discrete-response"><i class="fa fa-check"></i><b>5.2.2</b> Discrete Response</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#probabilistic-forecasts-subset-based-learning-methods"><i class="fa fa-check"></i><b>5.3</b> Probabilistic Forecasts: subset-based learning methods</a><ul>
<li class="chapter" data-level="5.3.1" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#the-techniques"><i class="fa fa-check"></i><b>5.3.1</b> The techniques</a></li>
<li class="chapter" data-level="5.3.2" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#exercise"><i class="fa fa-check"></i><b>5.3.2</b> Exercise</a></li>
<li class="chapter" data-level="5.3.3" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#bias-variance-tradeoff"><i class="fa fa-check"></i><b>5.3.3</b> Bias-variance tradeoff</a></li>
<li class="chapter" data-level="5.3.4" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#evaluating-model-goodness"><i class="fa fa-check"></i><b>5.3.4</b> Evaluating Model Goodness</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#discussion-points"><i class="fa fa-check"></i><b>5.4</b> Discussion Points</a></li>
<li class="chapter" data-level="5.5" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#when-are-they-not-useful"><i class="fa fa-check"></i><b>5.5</b> When are they not useful?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="quantile-regression.html"><a href="quantile-regression.html"><i class="fa fa-check"></i><b>6</b> Quantile Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="quantile-regression.html"><a href="quantile-regression.html#what-is-the-mean-anyway"><i class="fa fa-check"></i><b>6.1</b> What is the mean, anyway?</a></li>
<li class="chapter" data-level="6.2" data-path="quantile-regression.html"><a href="quantile-regression.html#linear-quantile-regression"><i class="fa fa-check"></i><b>6.2</b> Linear Quantile Regression</a></li>
<li class="chapter" data-level="6.3" data-path="quantile-regression.html"><a href="quantile-regression.html#exercise-1"><i class="fa fa-check"></i><b>6.3</b> Exercise</a></li>
<li class="chapter" data-level="6.4" data-path="quantile-regression.html"><a href="quantile-regression.html#problem-crossing-quantiles"><i class="fa fa-check"></i><b>6.4</b> Problem: Crossing quantiles</a></li>
<li class="chapter" data-level="6.5" data-path="quantile-regression.html"><a href="quantile-regression.html#problem-upper-quantiles"><i class="fa fa-check"></i><b>6.5</b> Problem: Upper quantiles</a></li>
<li class="chapter" data-level="6.6" data-path="quantile-regression.html"><a href="quantile-regression.html#evaluating-model-goodness-1"><i class="fa fa-check"></i><b>6.6</b> Evaluating Model Goodness</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html"><i class="fa fa-check"></i><b>7</b> Introduction to Machine Learning</a><ul>
<li class="chapter" data-level="7.1" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#what-machine-learning-is"><i class="fa fa-check"></i><b>7.1</b> What machine learning is</a></li>
<li class="chapter" data-level="7.2" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#variable-terminology"><i class="fa fa-check"></i><b>7.2</b> Variable terminology</a><ul>
<li class="chapter" data-level="7.2.1" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#variable-types"><i class="fa fa-check"></i><b>7.2.1</b> Variable types</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#types-of-supervised-learning"><i class="fa fa-check"></i><b>7.3</b> Types of Supervised Learning</a></li>
<li class="chapter" data-level="7.4" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#together-linear-regression-example"><i class="fa fa-check"></i><b>7.4</b> Together: Linear Regression Example</a></li>
<li class="chapter" data-level="7.5" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#irreducible-error"><i class="fa fa-check"></i><b>7.5</b> Irreducible Error</a></li>
<li class="chapter" data-level="7.6" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#in-class-exercises-irreducible-error"><i class="fa fa-check"></i><b>7.6</b> In-class Exercises: Irreducible Error</a><ul>
<li class="chapter" data-level="7.6.1" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#oracle-regression"><i class="fa fa-check"></i><b>7.6.1</b> Oracle regression</a></li>
<li class="chapter" data-level="7.6.2" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#oracle-classification"><i class="fa fa-check"></i><b>7.6.2</b> Oracle classification</a></li>
<li class="chapter" data-level="7.6.3" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#bonus-random-prediction"><i class="fa fa-check"></i><b>7.6.3</b> (BONUS) Random prediction</a></li>
<li class="chapter" data-level="7.6.4" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#bonus-a-more-non-standard-regression"><i class="fa fa-check"></i><b>7.6.4</b> (BONUS) A more non-standard regression</a></li>
<li class="chapter" data-level="7.6.5" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#bonus-oracle-mse"><i class="fa fa-check"></i><b>7.6.5</b> (BONUS) Oracle MSE</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html"><i class="fa fa-check"></i><b>8</b> Regression in the context of problem solving</a><ul>
<li class="chapter" data-level="8.1" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#communicating-distillation-3-4"><i class="fa fa-check"></i><b>8.1</b> Communicating (Distillation 3-4)</a></li>
<li class="chapter" data-level="8.2" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#modelling-distillation-2-3"><i class="fa fa-check"></i><b>8.2</b> Modelling (Distillation 2-3)</a></li>
<li class="chapter" data-level="8.3" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#asking-useful-statistical-questions-distillation-1-2"><i class="fa fa-check"></i><b>8.3</b> Asking useful statistical questions (Distillation 1-2)</a><ul>
<li class="chapter" data-level="8.3.1" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#business-objectives-examples"><i class="fa fa-check"></i><b>8.3.1</b> Business objectives: examples</a></li>
<li class="chapter" data-level="8.3.2" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#statistical-objectives-refining"><i class="fa fa-check"></i><b>8.3.2</b> Statistical objectives: refining</a></li>
<li class="chapter" data-level="8.3.3" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#statistical-objectives-examples"><i class="fa fa-check"></i><b>8.3.3</b> Statistical objectives: examples</a></li>
<li class="chapter" data-level="8.3.4" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#statistical-questions-are-not-the-full-picture"><i class="fa fa-check"></i><b>8.3.4</b> Statistical questions are not the full picture</a></li>
<li class="chapter" data-level="8.3.5" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#statistical-objectives-unrelated-to-supervised-learning"><i class="fa fa-check"></i><b>8.3.5</b> Statistical objectives unrelated to supervised learning</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#prerequisites-to-an-analysis"><i class="fa fa-check"></i><b>8.4</b> Prerequisites to an analysis</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="local-regression.html"><a href="local-regression.html"><i class="fa fa-check"></i><b>9</b> Local Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="local-regression.html"><a href="local-regression.html#knn"><i class="fa fa-check"></i><b>9.1</b> kNN</a></li>
<li class="chapter" data-level="9.2" data-path="local-regression.html"><a href="local-regression.html#loess"><i class="fa fa-check"></i><b>9.2</b> loess</a></li>
<li class="chapter" data-level="9.3" data-path="local-regression.html"><a href="local-regression.html#in-class-exercises"><i class="fa fa-check"></i><b>9.3</b> In-Class Exercises</a><ul>
<li class="chapter" data-level="9.3.1" data-path="local-regression.html"><a href="local-regression.html#exercise-1-mean-at-x0"><i class="fa fa-check"></i><b>9.3.1</b> Exercise 1: Mean at <span class="math inline">\(X=0\)</span></a></li>
<li class="chapter" data-level="9.3.2" data-path="local-regression.html"><a href="local-regression.html#exercise-2-regression-curve"><i class="fa fa-check"></i><b>9.3.2</b> Exercise 2: Regression Curve</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="local-regression.html"><a href="local-regression.html#hyperparameters-and-the-biasvariance-tradeoff"><i class="fa fa-check"></i><b>9.4</b> Hyperparameters and the bias/variance tradeoff</a></li>
<li class="chapter" data-level="9.5" data-path="local-regression.html"><a href="local-regression.html#extensions-to-knn-and-loess"><i class="fa fa-check"></i><b>9.5</b> Extensions to kNN and loess</a><ul>
<li class="chapter" data-level="9.5.1" data-path="local-regression.html"><a href="local-regression.html#kernel-weighting"><i class="fa fa-check"></i><b>9.5.1</b> Kernel weighting</a></li>
<li class="chapter" data-level="9.5.2" data-path="local-regression.html"><a href="local-regression.html#local-polynomials"><i class="fa fa-check"></i><b>9.5.2</b> Local polynomials</a></li>
<li class="chapter" data-level="9.5.3" data-path="local-regression.html"><a href="local-regression.html#combination"><i class="fa fa-check"></i><b>9.5.3</b> Combination</a></li>
<li class="chapter" data-level="9.5.4" data-path="local-regression.html"><a href="local-regression.html#other-distances"><i class="fa fa-check"></i><b>9.5.4</b> Other distances</a></li>
<li class="chapter" data-level="9.5.5" data-path="local-regression.html"><a href="local-regression.html#scaling"><i class="fa fa-check"></i><b>9.5.5</b> Scaling</a></li>
<li class="chapter" data-level="9.5.6" data-path="local-regression.html"><a href="local-regression.html#demonstration"><i class="fa fa-check"></i><b>9.5.6</b> Demonstration</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="local-regression.html"><a href="local-regression.html#model-assumptions-and-the-biasvariance-tradeoff"><i class="fa fa-check"></i><b>9.6</b> Model assumptions and the bias/variance tradeoff</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="reducible-error.html"><a href="reducible-error.html"><i class="fa fa-check"></i><b>10</b> Reducible Error</a><ul>
<li class="chapter" data-level="10.1" data-path="reducible-error.html"><a href="reducible-error.html#classification-exercise-do-together"><i class="fa fa-check"></i><b>10.1</b> Classification Exercise: Do Together</a></li>
<li class="chapter" data-level="10.2" data-path="reducible-error.html"><a href="reducible-error.html#training-error-vs.generalization-error"><i class="fa fa-check"></i><b>10.2</b> Training Error vs. Generalization Error</a></li>
<li class="chapter" data-level="10.3" data-path="reducible-error.html"><a href="reducible-error.html#model-complexity"><i class="fa fa-check"></i><b>10.3</b> Model complexity</a><ul>
<li class="chapter" data-level="10.3.1" data-path="reducible-error.html"><a href="reducible-error.html#activity"><i class="fa fa-check"></i><b>10.3.1</b> Activity</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="reducible-error.html"><a href="reducible-error.html#reducible-error-1"><i class="fa fa-check"></i><b>10.4</b> Reducible Error</a><ul>
<li class="chapter" data-level="10.4.1" data-path="reducible-error.html"><a href="reducible-error.html#what-is-it"><i class="fa fa-check"></i><b>10.4.1</b> What is it?</a></li>
<li class="chapter" data-level="10.4.2" data-path="reducible-error.html"><a href="reducible-error.html#example"><i class="fa fa-check"></i><b>10.4.2</b> Example</a></li>
<li class="chapter" data-level="10.4.3" data-path="reducible-error.html"><a href="reducible-error.html#bias-and-variance"><i class="fa fa-check"></i><b>10.4.3</b> Bias and Variance</a></li>
<li class="chapter" data-level="10.4.4" data-path="reducible-error.html"><a href="reducible-error.html#reducing-reducible-error"><i class="fa fa-check"></i><b>10.4.4</b> Reducing reducible error</a></li>
<li class="chapter" data-level="10.4.5" data-path="reducible-error.html"><a href="reducible-error.html#error-decomposition"><i class="fa fa-check"></i><b>10.4.5</b> Error decomposition</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="model-selection.html"><a href="model-selection.html"><i class="fa fa-check"></i><b>11</b> Model Selection</a><ul>
<li class="chapter" data-level="11.1" data-path="model-selection.html"><a href="model-selection.html#exercise-cv"><i class="fa fa-check"></i><b>11.1</b> Exercise: CV</a></li>
<li class="chapter" data-level="11.2" data-path="model-selection.html"><a href="model-selection.html#out-of-sample-error"><i class="fa fa-check"></i><b>11.2</b> Out-of-sample Error</a><ul>
<li class="chapter" data-level="11.2.1" data-path="model-selection.html"><a href="model-selection.html#the-fundamental-problem"><i class="fa fa-check"></i><b>11.2.1</b> The fundamental problem</a></li>
<li class="chapter" data-level="11.2.2" data-path="model-selection.html"><a href="model-selection.html#solution-1-use-a-hold-out-set."><i class="fa fa-check"></i><b>11.2.2</b> Solution 1: Use a hold-out set.</a></li>
<li class="chapter" data-level="11.2.3" data-path="model-selection.html"><a href="model-selection.html#solution-2-cross-validation"><i class="fa fa-check"></i><b>11.2.3</b> Solution 2: Cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="model-selection.html"><a href="model-selection.html#alternative-measures-of-model-goodness"><i class="fa fa-check"></i><b>11.3</b> Alternative measures of model goodness</a></li>
<li class="chapter" data-level="11.4" data-path="model-selection.html"><a href="model-selection.html#feature-and-model-selection-setup"><i class="fa fa-check"></i><b>11.4</b> Feature and model selection: setup</a></li>
<li class="chapter" data-level="11.5" data-path="model-selection.html"><a href="model-selection.html#model-selection-1"><i class="fa fa-check"></i><b>11.5</b> Model selection</a></li>
<li class="chapter" data-level="11.6" data-path="model-selection.html"><a href="model-selection.html#feature-predictor-selection"><i class="fa fa-check"></i><b>11.6</b> Feature (predictor) selection</a><ul>
<li class="chapter" data-level="11.6.1" data-path="model-selection.html"><a href="model-selection.html#specialized-metrics-for-feature-selection"><i class="fa fa-check"></i><b>11.6.1</b> Specialized metrics for feature selection</a></li>
<li class="chapter" data-level="11.6.2" data-path="model-selection.html"><a href="model-selection.html#greedy-selection"><i class="fa fa-check"></i><b>11.6.2</b> Greedy Selection</a></li>
<li class="chapter" data-level="11.6.3" data-path="model-selection.html"><a href="model-selection.html#regularization"><i class="fa fa-check"></i><b>11.6.3</b> Regularization</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="splines-and-loess-regression.html"><a href="splines-and-loess-regression.html"><i class="fa fa-check"></i><b>12</b> Splines and Loess Regression</a><ul>
<li class="chapter" data-level="12.1" data-path="splines-and-loess-regression.html"><a href="splines-and-loess-regression.html#loess-1"><i class="fa fa-check"></i><b>12.1</b> Loess</a><ul>
<li class="chapter" data-level="12.1.1" data-path="splines-and-loess-regression.html"><a href="splines-and-loess-regression.html#the-moving-window"><i class="fa fa-check"></i><b>12.1.1</b> The “Moving Window”</a></li>
<li class="chapter" data-level="12.1.2" data-path="splines-and-loess-regression.html"><a href="splines-and-loess-regression.html#ggplot2"><i class="fa fa-check"></i><b>12.1.2</b> <code>ggplot2</code></a></li>
<li class="chapter" data-level="12.1.3" data-path="splines-and-loess-regression.html"><a href="splines-and-loess-regression.html#manual-method"><i class="fa fa-check"></i><b>12.1.3</b> Manual method</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="model-fitting-in-r.html"><a href="model-fitting-in-r.html"><i class="fa fa-check"></i><b>13</b> Model fitting in R</a><ul>
<li class="chapter" data-level="13.1" data-path="model-fitting-in-r.html"><a href="model-fitting-in-r.html#broom-package"><i class="fa fa-check"></i><b>13.1</b> <code>broom</code> package</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>14</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="14.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#model-specification"><i class="fa fa-check"></i><b>14.1</b> Model Specification</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="linear-models-in-general.html"><a href="linear-models-in-general.html"><i class="fa fa-check"></i><b>15</b> Linear models in general</a></li>
<li class="chapter" data-level="16" data-path="reference-treatment-parameterization.html"><a href="reference-treatment-parameterization.html"><i class="fa fa-check"></i><b>16</b> reference-treatment parameterization</a><ul>
<li class="chapter" data-level="16.1" data-path="reference-treatment-parameterization.html"><a href="reference-treatment-parameterization.html#more-than-one-category-lab-2"><i class="fa fa-check"></i><b>16.1</b> More than one category (Lab 2)</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="non-identifiability-in-gams.html"><a href="non-identifiability-in-gams.html"><i class="fa fa-check"></i><b>17</b> Non-identifiability in GAMS</a><ul>
<li class="chapter" data-level="17.1" data-path="non-identifiability-in-gams.html"><a href="non-identifiability-in-gams.html#non-identifiability"><i class="fa fa-check"></i><b>17.1</b> Non-identifiability</a></li>
<li class="chapter" data-level="17.2" data-path="non-identifiability-in-gams.html"><a href="non-identifiability-in-gams.html#question-1b"><i class="fa fa-check"></i><b>17.2</b> Question 1b</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>18</b> ANOVA</a><ul>
<li class="chapter" data-level="18.1" data-path="anova.html"><a href="anova.html#the-types-of-parametric-assumptions"><i class="fa fa-check"></i><b>18.1</b> The types of parametric assumptions</a><ul>
<li class="chapter" data-level="18.1.1" data-path="anova.html"><a href="anova.html#when-defining-a-model-function."><i class="fa fa-check"></i><b>18.1.1</b> 1. When defining a <strong>model function</strong>.</a></li>
<li class="chapter" data-level="18.1.2" data-path="anova.html"><a href="anova.html#when-defining-probability-distributions."><i class="fa fa-check"></i><b>18.1.2</b> 2. When defining <strong>probability distributions</strong>.</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="anova.html"><a href="anova.html#the-value-of-making-parametric-assumptions"><i class="fa fa-check"></i><b>18.2</b> The value of making parametric assumptions</a><ul>
<li class="chapter" data-level="18.2.1" data-path="anova.html"><a href="anova.html#value-1-reduced-error"><i class="fa fa-check"></i><b>18.2.1</b> Value #1: Reduced Error</a></li>
<li class="chapter" data-level="18.2.2" data-path="anova.html"><a href="anova.html#value-2-interpretation"><i class="fa fa-check"></i><b>18.2.2</b> Value #2: Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="anova.html"><a href="anova.html#problems"><i class="fa fa-check"></i><b>18.3</b> Problems</a></li>
<li class="chapter" data-level="18.4" data-path="anova.html"><a href="anova.html#solutions"><i class="fa fa-check"></i><b>18.4</b> Solutions</a><ul>
<li class="chapter" data-level="18.4.1" data-path="anova.html"><a href="anova.html#solution-1-transformations"><i class="fa fa-check"></i><b>18.4.1</b> Solution 1: Transformations</a></li>
<li class="chapter" data-level="18.4.2" data-path="anova.html"><a href="anova.html#solution-2-link-functions"><i class="fa fa-check"></i><b>18.4.2</b> Solution 2: Link Functions</a></li>
<li class="chapter" data-level="18.4.3" data-path="anova.html"><a href="anova.html#solution-3-scientifically-backed-functions"><i class="fa fa-check"></i><b>18.4.3</b> Solution 3: Scientifically-backed functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="glms-in-r.html"><a href="glms-in-r.html"><i class="fa fa-check"></i><b>19</b> GLM’s in R</a><ul>
<li class="chapter" data-level="19.0.1" data-path="glms-in-r.html"><a href="glms-in-r.html#broomaugment"><i class="fa fa-check"></i><b>19.0.1</b> <code>broom::augment()</code></a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="logistic-regression-paper-with-paul.html"><a href="logistic-regression-paper-with-paul.html"><i class="fa fa-check"></i><b>20</b> Logistic Regression paper with Paul</a><ul>
<li class="chapter" data-level="20.1" data-path="logistic-regression-paper-with-paul.html"><a href="logistic-regression-paper-with-paul.html#the-traditional-approach"><i class="fa fa-check"></i><b>20.1</b> The Traditional Approach</a><ul>
<li class="chapter" data-level="20.1.1" data-path="logistic-regression-paper-with-paul.html"><a href="logistic-regression-paper-with-paul.html#the-linear-probability-model"><i class="fa fa-check"></i><b>20.1.1</b> The Linear Probability Model</a></li>
<li class="chapter" data-level="20.1.2" data-path="logistic-regression-paper-with-paul.html"><a href="logistic-regression-paper-with-paul.html#the-logistic-model"><i class="fa fa-check"></i><b>20.1.2</b> The Logistic Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="robust-regression-in-r.html"><a href="robust-regression-in-r.html"><i class="fa fa-check"></i><b>21</b> Robust Regression in R</a><ul>
<li class="chapter" data-level="21.0.1" data-path="robust-regression-in-r.html"><a href="robust-regression-in-r.html#heavy-tailed-regression"><i class="fa fa-check"></i><b>21.0.1</b> Heavy Tailed Regression</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="from-linear-regression-to-mixed-effects-models.html"><a href="from-linear-regression-to-mixed-effects-models.html"><i class="fa fa-check"></i><b>22</b> From Linear Regression to Mixed Effects Models</a><ul>
<li class="chapter" data-level="22.1" data-path="from-linear-regression-to-mixed-effects-models.html"><a href="from-linear-regression-to-mixed-effects-models.html#motivation-for-lme"><i class="fa fa-check"></i><b>22.1</b> Motivation for LME</a></li>
<li class="chapter" data-level="22.2" data-path="from-linear-regression-to-mixed-effects-models.html"><a href="from-linear-regression-to-mixed-effects-models.html#definition"><i class="fa fa-check"></i><b>22.2</b> Definition</a></li>
<li class="chapter" data-level="22.3" data-path="from-linear-regression-to-mixed-effects-models.html"><a href="from-linear-regression-to-mixed-effects-models.html#r-tools-for-fitting"><i class="fa fa-check"></i><b>22.3</b> R Tools for Fitting</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="mixed-effects-models-in-r-tutorial.html"><a href="mixed-effects-models-in-r-tutorial.html"><i class="fa fa-check"></i><b>23</b> Mixed Effects Models in R: tutorial</a></li>
<li class="chapter" data-level="24" data-path="dsci-562-tutorial-missing-data.html"><a href="dsci-562-tutorial-missing-data.html"><i class="fa fa-check"></i><b>24</b> DSCI 562 Tutorial: Missing Data</a><ul>
<li class="chapter" data-level="24.1" data-path="dsci-562-tutorial-missing-data.html"><a href="dsci-562-tutorial-missing-data.html#mean-imputation"><i class="fa fa-check"></i><b>24.1</b> Mean Imputation</a></li>
<li class="chapter" data-level="24.2" data-path="dsci-562-tutorial-missing-data.html"><a href="dsci-562-tutorial-missing-data.html#multiple-imputation"><i class="fa fa-check"></i><b>24.2</b> Multiple Imputation</a><ul>
<li class="chapter" data-level="24.2.1" data-path="dsci-562-tutorial-missing-data.html"><a href="dsci-562-tutorial-missing-data.html#patterns"><i class="fa fa-check"></i><b>24.2.1</b> Patterns</a></li>
<li class="chapter" data-level="24.2.2" data-path="dsci-562-tutorial-missing-data.html"><a href="dsci-562-tutorial-missing-data.html#multiple-imputation-1"><i class="fa fa-check"></i><b>24.2.2</b> Multiple Imputation</a></li>
<li class="chapter" data-level="24.2.3" data-path="dsci-562-tutorial-missing-data.html"><a href="dsci-562-tutorial-missing-data.html#pooling"><i class="fa fa-check"></i><b>24.2.3</b> Pooling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="spatial.html"><a href="spatial.html"><i class="fa fa-check"></i><b>25</b> Spatial</a><ul>
<li class="chapter" data-level="25.1" data-path="spatial.html"><a href="spatial.html#a-model-for-river-rock-size"><i class="fa fa-check"></i><b>25.1</b> A Model for River Rock Size</a></li>
<li class="chapter" data-level="25.2" data-path="spatial.html"><a href="spatial.html#statistical-objectives"><i class="fa fa-check"></i><b>25.2</b> Statistical Objectives</a><ul>
<li class="chapter" data-level="25.2.1" data-path="spatial.html"><a href="spatial.html#preliminaries-variance-and-correlation"><i class="fa fa-check"></i><b>25.2.1</b> Preliminaries: Variance and Correlation</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="spatial.html"><a href="spatial.html#three-concepts"><i class="fa fa-check"></i><b>25.3</b> Three Concepts</a><ul>
<li class="chapter" data-level="25.3.1" data-path="spatial.html"><a href="spatial.html#error-variance-sigma_e2leftxright"><i class="fa fa-check"></i><b>25.3.1</b> Error Variance <span class="math inline">\(\sigma_{E}^{2}\left(x\right)\)</span></a></li>
<li class="chapter" data-level="25.3.2" data-path="spatial.html"><a href="spatial.html#mean-variance-sigma_m2"><i class="fa fa-check"></i><b>25.3.2</b> Mean Variance <span class="math inline">\(\sigma_{M}^{2}\)</span></a></li>
<li class="chapter" data-level="25.3.3" data-path="spatial.html"><a href="spatial.html#mean-correlation-rholeftdright"><i class="fa fa-check"></i><b>25.3.3</b> Mean Correlation <span class="math inline">\(\rho\left(d\right)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="25.4" data-path="spatial.html"><a href="spatial.html#estimation-1"><i class="fa fa-check"></i><b>25.4</b> Estimation</a><ul>
<li class="chapter" data-level="25.4.1" data-path="spatial.html"><a href="spatial.html#constant-error-variance"><i class="fa fa-check"></i><b>25.4.1</b> Constant Error Variance</a></li>
<li class="chapter" data-level="25.4.2" data-path="spatial.html"><a href="spatial.html#non-constant-error-variance"><i class="fa fa-check"></i><b>25.4.2</b> Non-Constant Error Variance</a></li>
</ul></li>
<li class="chapter" data-level="25.5" data-path="spatial.html"><a href="spatial.html#statistical-objective-1-downstream-fining-curve"><i class="fa fa-check"></i><b>25.5</b> Statistical Objective 1: Downstream Fining Curve</a><ul>
<li class="chapter" data-level="25.5.1" data-path="spatial.html"><a href="spatial.html#regression-form"><i class="fa fa-check"></i><b>25.5.1</b> Regression Form</a></li>
</ul></li>
<li class="chapter" data-level="25.6" data-path="spatial.html"><a href="spatial.html#statistical-objective-2-river-profile"><i class="fa fa-check"></i><b>25.6</b> Statistical Objective 2: River Profile</a><ul>
<li class="chapter" data-level="25.6.1" data-path="spatial.html"><a href="spatial.html#simple-kriging"><i class="fa fa-check"></i><b>25.6.1</b> Simple Kriging</a></li>
<li class="chapter" data-level="25.6.2" data-path="spatial.html"><a href="spatial.html#universal-kriging"><i class="fa fa-check"></i><b>25.6.2</b> Universal Kriging</a></li>
<li class="chapter" data-level="25.6.3" data-path="spatial.html"><a href="spatial.html#kriging-under-non-constant-error-variance"><i class="fa fa-check"></i><b>25.6.3</b> Kriging under Non-Constant Error Variance</a></li>
</ul></li>
<li class="chapter" data-level="25.7" data-path="spatial.html"><a href="spatial.html#confidence-intervals-of-the-river-profile"><i class="fa fa-check"></i><b>25.7</b> Confidence Intervals of the River Profile</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="timeseries-in-base-r.html"><a href="timeseries-in-base-r.html"><i class="fa fa-check"></i><b>26</b> Timeseries in (base) R</a></li>
<li class="divider"></li>
<li><a href="https://github.com/vincenzocoia/Interpreting-Regression" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpreting Regression</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="from-linear-regression-to-mixed-effects-models" class="section level1">
<h1><span class="header-section-number">Chapter 22</span> From Linear Regression to Mixed Effects Models</h1>
<p><strong>Caution: in a highly developmental stage! See Section <a href="index.html#caution">1.1</a>.</strong></p>
<div id="motivation-for-lme" class="section level2">
<h2><span class="header-section-number">22.1</span> Motivation for LME</h2>
<p>Let’s take a look at the <code>esoph</code> data set, to see how the number of controls <code>ncontrols</code> affects the number of cases <code>ncases</code> of cancer for each age group <code>agegp</code>. Here’s what the data look like (with a tad bit of vertical jitter):</p>
<pre><code>## -------------------------------------------------------------------------</code></pre>
<pre><code>## You have loaded plyr after dplyr - this is likely to cause problems.
## If you need functions from both plyr and dplyr, please load plyr first, then dplyr:
## library(plyr); library(dplyr)</code></pre>
<pre><code>## -------------------------------------------------------------------------</code></pre>
<pre><code>## 
## Attaching package: &#39;plyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:dplyr&#39;:
## 
##     arrange, count, desc, failwith, id, mutate, rename, summarise,
##     summarize</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     compact</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-80-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>It seems each age group has a different relationship. Should we then fit regression lines for each group separately? Here’s what we get, if we do:</p>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-81-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>But, each group has so few observations, making the regression less powerful:</p>
<pre><code>##    n
## 1 88</code></pre>
<p><strong>Question</strong>: can we borrow information across groups to strengthen regression, while still allowing each group to have its own regression line?</p>
<p>Yes – we can use <em>Linear Mixed Effects</em> (LME) models. An LME model is just a linear regression model for each group, with different slopes and intercepts, but the collection of slopes and intercepts <em>is assumed to come from some normal distribution</em>.</p>
</div>
<div id="definition" class="section level2">
<h2><span class="header-section-number">22.2</span> Definition</h2>
<p>With one predictor (<span class="math inline">\(X\)</span>), we can write an LME as follows: <span class="math display">\[ Y = \left(\beta_0 + b_0\right) + \left(\beta_1 + b_1\right) X + \varepsilon,  \]</span> where the error term <span class="math inline">\(\varepsilon\)</span> has mean zero, and the <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span> terms are normally distributed having a mean of zero, and some unknown variances and correlation. The <span class="math inline">\(\beta\)</span> terms are called the <em>fixed effects</em>, and the <span class="math inline">\(b\)</span> terms are called the <em>random effects</em>. Since the model has both types of effects, it’s said to be a <em>mixed</em> model – hence the name of “LME”.</p>
<p>Note that we don’t have to make <em>both</em> the slope and intercept random. For example, we can remove the <span class="math inline">\(b_0\)</span> term, which would mean that each group is forced to have the same (fixed) intercept <span class="math inline">\(\beta_0\)</span>. Also, we can add more predictors (<span class="math inline">\(X\)</span> variables).</p>
</div>
<div id="r-tools-for-fitting" class="section level2">
<h2><span class="header-section-number">22.3</span> R Tools for Fitting</h2>
<p>Two R packages exist for working with mixed effects models: <code>lme4</code> and <code>nlme</code>. We’ll be using the <code>lme4</code> package (check out <a href="http://stats.stackexchange.com/questions/5344/how-to-choose-nlme-or-lme4-r-library-for-mixed-effects-models">this</a> discussion on Cross Validated for a comparison of the two packages).</p>
<p>Let’s fit the model. We need to indicate a formula first in the <code>lmer</code> function, and indicate the data set we’re using.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(lme4)</code></pre></div>
<pre><code>## Loading required package: Matrix</code></pre>
<pre><code>## 
## Attaching package: &#39;Matrix&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:tidyr&#39;:
## 
##     expand</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit &lt;-<span class="st"> </span><span class="kw">lmer</span>(ncases <span class="op">~</span><span class="st"> </span>ncontrols <span class="op">+</span><span class="st"> </span>(ncontrols <span class="op">|</span><span class="st"> </span>agegp), 
            <span class="dt">data=</span>dat)</code></pre></div>
<p>Let’s take a closer look at the <em>formula</em>, which in this case is <code>ncases ~ ncontrols + (ncontrols | agegp)</code>.</p>
<p>On the left of the <code>~</code> is the response variable, as usual (just like for <code>lm</code>). On the right, we need to specify both the fixed and random effects. The fixed effects part is the same as usual: <code>ncontrols</code> indicates the explanatory variables that get a fixed effect. Then, we need to indicate which explanatory variables get a random effect. The random effects can be indicated in parentheses, separated by <code>+</code>, followed by a <code>|</code>, after which the variable(s) that you wish to group by are indicated. So <code>|</code> can be interpreted as “grouped by”.</p>
<p>Now let’s look at the model output:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(fit)</code></pre></div>
<pre><code>## Linear mixed model fit by REML [&#39;lmerMod&#39;]
## Formula: ncases ~ ncontrols + (ncontrols | agegp)
##    Data: dat
## 
## REML criterion at convergence: 388.6
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.6510 -0.3710 -0.1301  0.3683  4.8056 
## 
## Random effects:
##  Groups   Name        Variance Std.Dev. Corr
##  agegp    (Intercept) 1.694453 1.30171      
##           ncontrols   0.005729 0.07569  0.26
##  Residual             3.732899 1.93207      
## Number of obs: 88, groups:  agegp, 6
## 
## Fixed effects:
##             Estimate Std. Error t value
## (Intercept)  1.63379    0.59994   2.723
## ncontrols    0.04971    0.03676   1.352
## 
## Correlation of Fixed Effects:
##           (Intr)
## ncontrols 0.038</code></pre>
<p>The random and fixed effects are indicated here.</p>
<ul>
<li>Under the “Random effects:” section, we have the variance of each random effect, and the lower part of the correlation matrix of these random effects.</li>
<li>Under the “Fixed effects:” section, we have the estimates of the fixed effects, as well as the uncertainty in the estimate (indicated by the Std. Error).</li>
</ul>
<p>We can extract the collection of slopes and intercepts for each group using the <code>coef</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(par_coll &lt;-<span class="st"> </span><span class="kw">coef</span>(fit)[[<span class="dv">1</span>]])</code></pre></div>
<pre><code>##       (Intercept)    ncontrols
## 25-34   0.2674067 -0.002914520
## 35-44   0.7227280 -0.001127293
## 45-54   2.2834139  0.036587885
## 55-64   3.5108403  0.064242966
## 65-74   1.8699415  0.171918181
## 75+     1.1484332  0.029581764</code></pre>
<p>Let’s put these regression lines on the plot:</p>
<pre><code>##    agegp (Intercept)  ncontrols.x     alcgp    tobgp ncases ncontrols.y
## 1  25-34   0.2674067 -0.002914520 0-39g/day 0-9g/day      0          40
## 2  25-34   0.2674067 -0.002914520 0-39g/day    10-19      0          10
## 3  25-34   0.2674067 -0.002914520 0-39g/day    20-29      0           6
## 4  25-34   0.2674067 -0.002914520 0-39g/day      30+      0           5
## 5  25-34   0.2674067 -0.002914520     40-79 0-9g/day      0          27
## 6  25-34   0.2674067 -0.002914520     40-79    10-19      0           7
## 7  25-34   0.2674067 -0.002914520     40-79    20-29      0           4
## 8  25-34   0.2674067 -0.002914520     40-79      30+      0           7
## 9  25-34   0.2674067 -0.002914520    80-119 0-9g/day      0           2
## 10 25-34   0.2674067 -0.002914520    80-119    10-19      0           1
## 11 25-34   0.2674067 -0.002914520    80-119      30+      0           2
## 12 25-34   0.2674067 -0.002914520      120+ 0-9g/day      0           1
## 13 25-34   0.2674067 -0.002914520      120+    10-19      1           1
## 14 25-34   0.2674067 -0.002914520      120+    20-29      0           1
## 15 25-34   0.2674067 -0.002914520      120+      30+      0           2
## 16 35-44   0.7227280 -0.001127293 0-39g/day 0-9g/day      0          60
## 17 35-44   0.7227280 -0.001127293 0-39g/day    10-19      1          14
## 18 35-44   0.7227280 -0.001127293 0-39g/day    20-29      0           7
## 19 35-44   0.7227280 -0.001127293 0-39g/day      30+      0           8
## 20 35-44   0.7227280 -0.001127293     40-79 0-9g/day      0          35
## 21 35-44   0.7227280 -0.001127293     40-79    10-19      3          23
## 22 35-44   0.7227280 -0.001127293     40-79    20-29      1          14
## 23 35-44   0.7227280 -0.001127293     40-79      30+      0           8
## 24 35-44   0.7227280 -0.001127293    80-119 0-9g/day      0          11
## 25 35-44   0.7227280 -0.001127293    80-119    10-19      0           6
## 26 35-44   0.7227280 -0.001127293    80-119    20-29      0           2
## 27 35-44   0.7227280 -0.001127293    80-119      30+      0           1
## 28 35-44   0.7227280 -0.001127293      120+ 0-9g/day      2           3
## 29 35-44   0.7227280 -0.001127293      120+    10-19      0           3
## 30 35-44   0.7227280 -0.001127293      120+    20-29      2           4
## 31 45-54   2.2834139  0.036587885 0-39g/day 0-9g/day      1          46
## 32 45-54   2.2834139  0.036587885 0-39g/day    10-19      0          18
## 33 45-54   2.2834139  0.036587885 0-39g/day    20-29      0          10
## 34 45-54   2.2834139  0.036587885 0-39g/day      30+      0           4
## 35 45-54   2.2834139  0.036587885     40-79 0-9g/day      6          38
## 36 45-54   2.2834139  0.036587885     40-79    10-19      4          21
## 37 45-54   2.2834139  0.036587885     40-79    20-29      5          15
## 38 45-54   2.2834139  0.036587885     40-79      30+      5           7
## 39 45-54   2.2834139  0.036587885    80-119 0-9g/day      3          16
## 40 45-54   2.2834139  0.036587885    80-119    10-19      6          14
## 41 45-54   2.2834139  0.036587885    80-119    20-29      1           5
## 42 45-54   2.2834139  0.036587885    80-119      30+      2           4
## 43 45-54   2.2834139  0.036587885      120+ 0-9g/day      4           4
## 44 45-54   2.2834139  0.036587885      120+    10-19      3           4
## 45 45-54   2.2834139  0.036587885      120+    20-29      2           3
## 46 45-54   2.2834139  0.036587885      120+      30+      4           4
## 47 55-64   3.5108403  0.064242966 0-39g/day 0-9g/day      2          49
## 48 55-64   3.5108403  0.064242966 0-39g/day    10-19      3          22
## 49 55-64   3.5108403  0.064242966 0-39g/day    20-29      3          12
## 50 55-64   3.5108403  0.064242966 0-39g/day      30+      4           6
## 51 55-64   3.5108403  0.064242966     40-79 0-9g/day      9          40
## 52 55-64   3.5108403  0.064242966     40-79    10-19      6          21
## 53 55-64   3.5108403  0.064242966     40-79    20-29      4          17
## 54 55-64   3.5108403  0.064242966     40-79      30+      3           6
## 55 55-64   3.5108403  0.064242966    80-119 0-9g/day      9          18
## 56 55-64   3.5108403  0.064242966    80-119    10-19      8          15
## 57 55-64   3.5108403  0.064242966    80-119    20-29      3           6
## 58 55-64   3.5108403  0.064242966    80-119      30+      4           4
## 59 55-64   3.5108403  0.064242966      120+ 0-9g/day      5          10
## 60 55-64   3.5108403  0.064242966      120+    10-19      6           7
## 61 55-64   3.5108403  0.064242966      120+    20-29      2           3
## 62 55-64   3.5108403  0.064242966      120+      30+      5           6
## 63 65-74   1.8699415  0.171918181 0-39g/day 0-9g/day      5          48
## 64 65-74   1.8699415  0.171918181 0-39g/day    10-19      4          14
## 65 65-74   1.8699415  0.171918181 0-39g/day    20-29      2           7
## 66 65-74   1.8699415  0.171918181 0-39g/day      30+      0           2
## 67 65-74   1.8699415  0.171918181     40-79 0-9g/day     17          34
## 68 65-74   1.8699415  0.171918181     40-79    10-19      3          10
## 69 65-74   1.8699415  0.171918181     40-79    20-29      5           9
## 70 65-74   1.8699415  0.171918181    80-119 0-9g/day      6          13
## 71 65-74   1.8699415  0.171918181    80-119    10-19      4          12
## 72 65-74   1.8699415  0.171918181    80-119    20-29      2           3
## 73 65-74   1.8699415  0.171918181    80-119      30+      1           1
## 74 65-74   1.8699415  0.171918181      120+ 0-9g/day      3           4
## 75 65-74   1.8699415  0.171918181      120+    10-19      1           2
## 76 65-74   1.8699415  0.171918181      120+    20-29      1           1
## 77 65-74   1.8699415  0.171918181      120+      30+      1           1
## 78   75+   1.1484332  0.029581764 0-39g/day 0-9g/day      1          18
## 79   75+   1.1484332  0.029581764 0-39g/day    10-19      2           6
## 80   75+   1.1484332  0.029581764 0-39g/day      30+      1           3
## 81   75+   1.1484332  0.029581764     40-79 0-9g/day      2           5
## 82   75+   1.1484332  0.029581764     40-79    10-19      1           3
## 83   75+   1.1484332  0.029581764     40-79    20-29      0           3
## 84   75+   1.1484332  0.029581764     40-79      30+      1           1
## 85   75+   1.1484332  0.029581764    80-119 0-9g/day      1           1
## 86   75+   1.1484332  0.029581764    80-119    10-19      1           1
## 87   75+   1.1484332  0.029581764      120+ 0-9g/day      2           2
## 88   75+   1.1484332  0.029581764      120+    10-19      1           1</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-86-1.png" width="384" style="display: block; margin: auto;" /></p>
<p>So, each group still gets its own regression line, but tying the parameters together with a normal distribution gives us a more powerful regression.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="robust-regression-in-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mixed-effects-models-in-r-tutorial.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/vincenzocoia/Interpreting-Regression/edit/master/130-lme.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
