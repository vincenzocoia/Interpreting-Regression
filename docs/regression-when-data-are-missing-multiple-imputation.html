<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 22 Regression when data are missing: multiple imputation | Interpreting Regression</title>
  <meta name="description" content="A book about the why of regression to help you make decisions about your analysis.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 22 Regression when data are missing: multiple imputation | Interpreting Regression" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="A book about the why of regression to help you make decisions about your analysis." />
  <meta name="github-repo" content="vincenzocoia/Interpreting-Regression" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 22 Regression when data are missing: multiple imputation | Interpreting Regression" />
  
  <meta name="twitter:description" content="A book about the why of regression to help you make decisions about your analysis." />
  

<meta name="author" content="Vincenzo Coia">


<meta name="date" content="2019-08-09">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="regression-when-data-are-ordinal.html">
<link rel="next" href="regression-under-many-groups-mixed-effects-models.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpreting Regression</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preamble</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#caution"><i class="fa fa-check"></i><b>1.1</b> Caution</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#purpose-of-the-book"><i class="fa fa-check"></i><b>1.2</b> Purpose of the book</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#tasks-that-motivate-regression"><i class="fa fa-check"></i><b>1.3</b> Tasks that motivate Regression</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#examples"><i class="fa fa-check"></i><b>1.4</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html"><i class="fa fa-check"></i><b>2</b> Regression in the context of problem solving</a><ul>
<li class="chapter" data-level="2.1" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#communicating-distillation-3-4"><i class="fa fa-check"></i><b>2.1</b> Communicating (Distillation 3-4)</a></li>
<li class="chapter" data-level="2.2" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#modelling-distillation-2-3"><i class="fa fa-check"></i><b>2.2</b> Modelling (Distillation 2-3)</a></li>
<li class="chapter" data-level="2.3" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#asking-useful-statistical-questions-distillation-1-2"><i class="fa fa-check"></i><b>2.3</b> Asking useful statistical questions (Distillation 1-2)</a><ul>
<li class="chapter" data-level="2.3.1" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#business-objectives-examples"><i class="fa fa-check"></i><b>2.3.1</b> Business objectives: examples</a></li>
<li class="chapter" data-level="2.3.2" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#statistical-objectives-refining"><i class="fa fa-check"></i><b>2.3.2</b> Statistical objectives: refining</a></li>
<li class="chapter" data-level="2.3.3" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#statistical-objectives-examples"><i class="fa fa-check"></i><b>2.3.3</b> Statistical objectives: examples</a></li>
<li class="chapter" data-level="2.3.4" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#statistical-questions-are-not-the-full-picture"><i class="fa fa-check"></i><b>2.3.4</b> Statistical questions are not the full picture</a></li>
<li class="chapter" data-level="2.3.5" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#statistical-objectives-unrelated-to-supervised-learning"><i class="fa fa-check"></i><b>2.3.5</b> Statistical objectives unrelated to supervised learning</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#prerequisites-to-an-analysis"><i class="fa fa-check"></i><b>2.4</b> Prerequisites to an analysis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="an-outcome-on-its-own.html"><a href="an-outcome-on-its-own.html"><i class="fa fa-check"></i>An outcome on its own</a></li>
<li class="chapter" data-level="3" data-path="distributions-uncertainty-is-worth-explaining.html"><a href="distributions-uncertainty-is-worth-explaining.html"><i class="fa fa-check"></i><b>3</b> Distributions: Uncertainty is worth explaining</a></li>
<li class="chapter" data-level="4" data-path="explaining-an-uncertain-outcome-interpretable-quantities.html"><a href="explaining-an-uncertain-outcome-interpretable-quantities.html"><i class="fa fa-check"></i><b>4</b> Explaining an uncertain outcome: interpretable quantities</a><ul>
<li class="chapter" data-level="4.1" data-path="explaining-an-uncertain-outcome-interpretable-quantities.html"><a href="explaining-an-uncertain-outcome-interpretable-quantities.html#probabilistic-quantities"><i class="fa fa-check"></i><b>4.1</b> Probabilistic Quantities</a></li>
<li class="chapter" data-level="4.2" data-path="explaining-an-uncertain-outcome-interpretable-quantities.html"><a href="explaining-an-uncertain-outcome-interpretable-quantities.html#what-is-the-mean-anyway"><i class="fa fa-check"></i><b>4.2</b> What is the mean, anyway?</a></li>
<li class="chapter" data-level="4.3" data-path="explaining-an-uncertain-outcome-interpretable-quantities.html"><a href="explaining-an-uncertain-outcome-interpretable-quantities.html#quantiles"><i class="fa fa-check"></i><b>4.3</b> Quantiles</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>5</b> Estimation</a><ul>
<li class="chapter" data-level="5.1" data-path="estimation.html"><a href="estimation.html#estimation-of-probabilistic-quantities"><i class="fa fa-check"></i><b>5.1</b> Estimation of Probabilistic Quantities</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="parametric-families-of-distributions.html"><a href="parametric-families-of-distributions.html"><i class="fa fa-check"></i><b>6</b> Parametric Families of Distributions</a><ul>
<li class="chapter" data-level="6.1" data-path="parametric-families-of-distributions.html"><a href="parametric-families-of-distributions.html#parametric-families-of-distributions-1"><i class="fa fa-check"></i><b>6.1</b> Parametric Families of Distributions</a></li>
<li class="chapter" data-level="6.2" data-path="parametric-families-of-distributions.html"><a href="parametric-families-of-distributions.html#analyses-under-a-distributional-assumption"><i class="fa fa-check"></i><b>6.2</b> Analyses under a Distributional Assumption</a><ul>
<li class="chapter" data-level="6.2.1" data-path="parametric-families-of-distributions.html"><a href="parametric-families-of-distributions.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>6.2.1</b> Maximum Likelihood Estimation</a></li>
<li class="chapter" data-level="6.2.2" data-path="parametric-families-of-distributions.html"><a href="parametric-families-of-distributions.html#usefulness-in-practice"><i class="fa fa-check"></i><b>6.2.2</b> Usefulness in Practice</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="prediction-harnessing-the-signal.html"><a href="prediction-harnessing-the-signal.html"><i class="fa fa-check"></i>Prediction: harnessing the signal</a></li>
<li class="chapter" data-level="7" data-path="reducing-uncertainty-of-the-outcome-including-predictors.html"><a href="reducing-uncertainty-of-the-outcome-including-predictors.html"><i class="fa fa-check"></i><b>7</b> Reducing uncertainty of the outcome: including predictors</a><ul>
<li class="chapter" data-level="7.1" data-path="reducing-uncertainty-of-the-outcome-including-predictors.html"><a href="reducing-uncertainty-of-the-outcome-including-predictors.html#variable-terminology"><i class="fa fa-check"></i><b>7.1</b> Variable terminology</a><ul>
<li class="chapter" data-level="7.1.1" data-path="reducing-uncertainty-of-the-outcome-including-predictors.html"><a href="reducing-uncertainty-of-the-outcome-including-predictors.html#variable-types"><i class="fa fa-check"></i><b>7.1.1</b> Variable types</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="reducing-uncertainty-of-the-outcome-including-predictors.html"><a href="reducing-uncertainty-of-the-outcome-including-predictors.html#irreducible-error"><i class="fa fa-check"></i><b>7.2</b> Irreducible Error</a></li>
<li class="chapter" data-level="7.3" data-path="reducing-uncertainty-of-the-outcome-including-predictors.html"><a href="reducing-uncertainty-of-the-outcome-including-predictors.html#in-class-exercises-irreducible-error"><i class="fa fa-check"></i><b>7.3</b> In-class Exercises: Irreducible Error</a><ul>
<li class="chapter" data-level="7.3.1" data-path="reducing-uncertainty-of-the-outcome-including-predictors.html"><a href="reducing-uncertainty-of-the-outcome-including-predictors.html#oracle-regression"><i class="fa fa-check"></i><b>7.3.1</b> Oracle regression</a></li>
<li class="chapter" data-level="7.3.2" data-path="reducing-uncertainty-of-the-outcome-including-predictors.html"><a href="reducing-uncertainty-of-the-outcome-including-predictors.html#oracle-classification"><i class="fa fa-check"></i><b>7.3.2</b> Oracle classification</a></li>
<li class="chapter" data-level="7.3.3" data-path="reducing-uncertainty-of-the-outcome-including-predictors.html"><a href="reducing-uncertainty-of-the-outcome-including-predictors.html#bonus-random-prediction"><i class="fa fa-check"></i><b>7.3.3</b> (BONUS) Random prediction</a></li>
<li class="chapter" data-level="7.3.4" data-path="reducing-uncertainty-of-the-outcome-including-predictors.html"><a href="reducing-uncertainty-of-the-outcome-including-predictors.html#bonus-a-more-non-standard-regression"><i class="fa fa-check"></i><b>7.3.4</b> (BONUS) A more non-standard regression</a></li>
<li class="chapter" data-level="7.3.5" data-path="reducing-uncertainty-of-the-outcome-including-predictors.html"><a href="reducing-uncertainty-of-the-outcome-including-predictors.html#bonus-oracle-mse"><i class="fa fa-check"></i><b>7.3.5</b> (BONUS) Oracle MSE</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="the-signal-model-functions.html"><a href="the-signal-model-functions.html"><i class="fa fa-check"></i><b>8</b> The signal: model functions</a><ul>
<li class="chapter" data-level="8.1" data-path="the-signal-model-functions.html"><a href="the-signal-model-functions.html#linear-quantile-regression"><i class="fa fa-check"></i><b>8.1</b> Linear Quantile Regression</a><ul>
<li class="chapter" data-level="8.1.1" data-path="the-signal-model-functions.html"><a href="the-signal-model-functions.html#exercise"><i class="fa fa-check"></i><b>8.1.1</b> Exercise</a></li>
<li class="chapter" data-level="8.1.2" data-path="the-signal-model-functions.html"><a href="the-signal-model-functions.html#problem-crossing-quantiles"><i class="fa fa-check"></i><b>8.1.2</b> Problem: Crossing quantiles</a></li>
<li class="chapter" data-level="8.1.3" data-path="the-signal-model-functions.html"><a href="the-signal-model-functions.html#problem-upper-quantiles"><i class="fa fa-check"></i><b>8.1.3</b> Problem: Upper quantiles</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="the-model-fitting-paradigm-in-r.html"><a href="the-model-fitting-paradigm-in-r.html"><i class="fa fa-check"></i><b>9</b> The Model-Fitting Paradigm in R</a><ul>
<li class="chapter" data-level="9.1" data-path="the-model-fitting-paradigm-in-r.html"><a href="the-model-fitting-paradigm-in-r.html#broom-package"><i class="fa fa-check"></i><b>9.1</b> <code>broom</code> package</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="estimating-parametric-model-functions.html"><a href="estimating-parametric-model-functions.html"><i class="fa fa-check"></i><b>10</b> Estimating parametric model functions</a><ul>
<li class="chapter" data-level="10.1" data-path="estimating-parametric-model-functions.html"><a href="estimating-parametric-model-functions.html#writing-the-sample-mean-as-an-optimization-problem"><i class="fa fa-check"></i><b>10.1</b> Writing the sample mean as an optimization problem</a></li>
<li class="chapter" data-level="10.2" data-path="estimating-parametric-model-functions.html"><a href="estimating-parametric-model-functions.html#evaluating-model-goodness-quantiles"><i class="fa fa-check"></i><b>10.2</b> Evaluating Model Goodness: Quantiles</a></li>
<li class="chapter" data-level="10.3" data-path="estimating-parametric-model-functions.html"><a href="estimating-parametric-model-functions.html#simple-linear-regression"><i class="fa fa-check"></i><b>10.3</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="10.3.1" data-path="estimating-parametric-model-functions.html"><a href="estimating-parametric-model-functions.html#model-specification"><i class="fa fa-check"></i><b>10.3.1</b> Model Specification</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="estimating-parametric-model-functions.html"><a href="estimating-parametric-model-functions.html#linear-models-in-general"><i class="fa fa-check"></i><b>10.4</b> Linear models in general</a></li>
<li class="chapter" data-level="10.5" data-path="estimating-parametric-model-functions.html"><a href="estimating-parametric-model-functions.html#reference-treatment-parameterization"><i class="fa fa-check"></i><b>10.5</b> reference-treatment parameterization</a><ul>
<li class="chapter" data-level="10.5.1" data-path="estimating-parametric-model-functions.html"><a href="estimating-parametric-model-functions.html#more-than-one-category-lab-2"><i class="fa fa-check"></i><b>10.5.1</b> More than one category (Lab 2)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="estimating-assumption-free-the-world-of-supervised-learning-techniques.html"><a href="estimating-assumption-free-the-world-of-supervised-learning-techniques.html"><i class="fa fa-check"></i><b>11</b> Estimating assumption-free: the world of supervised learning techniques</a><ul>
<li class="chapter" data-level="11.1" data-path="estimating-assumption-free-the-world-of-supervised-learning-techniques.html"><a href="estimating-assumption-free-the-world-of-supervised-learning-techniques.html#what-machine-learning-is"><i class="fa fa-check"></i><b>11.1</b> What machine learning is</a></li>
<li class="chapter" data-level="11.2" data-path="estimating-assumption-free-the-world-of-supervised-learning-techniques.html"><a href="estimating-assumption-free-the-world-of-supervised-learning-techniques.html#types-of-supervised-learning"><i class="fa fa-check"></i><b>11.2</b> Types of Supervised Learning</a></li>
<li class="chapter" data-level="11.3" data-path="estimating-assumption-free-the-world-of-supervised-learning-techniques.html"><a href="estimating-assumption-free-the-world-of-supervised-learning-techniques.html#local-regression"><i class="fa fa-check"></i><b>11.3</b> Local Regression</a><ul>
<li class="chapter" data-level="11.3.1" data-path="estimating-assumption-free-the-world-of-supervised-learning-techniques.html"><a href="estimating-assumption-free-the-world-of-supervised-learning-techniques.html#knn"><i class="fa fa-check"></i><b>11.3.1</b> kNN</a></li>
<li class="chapter" data-level="11.3.2" data-path="estimating-assumption-free-the-world-of-supervised-learning-techniques.html"><a href="estimating-assumption-free-the-world-of-supervised-learning-techniques.html#loess"><i class="fa fa-check"></i><b>11.3.2</b> loess</a></li>
<li class="chapter" data-level="11.3.3" data-path="estimating-assumption-free-the-world-of-supervised-learning-techniques.html"><a href="estimating-assumption-free-the-world-of-supervised-learning-techniques.html#in-class-exercises"><i class="fa fa-check"></i><b>11.3.3</b> In-Class Exercises</a></li>
<li class="chapter" data-level="11.3.4" data-path="estimating-assumption-free-the-world-of-supervised-learning-techniques.html"><a href="estimating-assumption-free-the-world-of-supervised-learning-techniques.html#hyperparameters-and-the-biasvariance-tradeoff"><i class="fa fa-check"></i><b>11.3.4</b> Hyperparameters and the bias/variance tradeoff</a></li>
<li class="chapter" data-level="11.3.5" data-path="estimating-assumption-free-the-world-of-supervised-learning-techniques.html"><a href="estimating-assumption-free-the-world-of-supervised-learning-techniques.html#extensions-to-knn-and-loess"><i class="fa fa-check"></i><b>11.3.5</b> Extensions to kNN and loess</a></li>
<li class="chapter" data-level="11.3.6" data-path="estimating-assumption-free-the-world-of-supervised-learning-techniques.html"><a href="estimating-assumption-free-the-world-of-supervised-learning-techniques.html#model-assumptions-and-the-biasvariance-tradeoff"><i class="fa fa-check"></i><b>11.3.6</b> Model assumptions and the bias/variance tradeoff</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="estimating-assumption-free-the-world-of-supervised-learning-techniques.html"><a href="estimating-assumption-free-the-world-of-supervised-learning-techniques.html#splines-and-loess-regression"><i class="fa fa-check"></i><b>11.4</b> Splines and Loess Regression</a><ul>
<li class="chapter" data-level="11.4.1" data-path="estimating-assumption-free-the-world-of-supervised-learning-techniques.html"><a href="estimating-assumption-free-the-world-of-supervised-learning-techniques.html#loess-1"><i class="fa fa-check"></i><b>11.4.1</b> Loess</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html"><i class="fa fa-check"></i><b>12</b> Overfitting: The problem with adding too many parameters</a><ul>
<li class="chapter" data-level="12.1" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#classification-exercise-do-together"><i class="fa fa-check"></i><b>12.1</b> Classification Exercise: Do Together</a></li>
<li class="chapter" data-level="12.2" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#training-error-vs.generalization-error"><i class="fa fa-check"></i><b>12.2</b> Training Error vs. Generalization Error</a></li>
<li class="chapter" data-level="12.3" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#model-complexity"><i class="fa fa-check"></i><b>12.3</b> Model complexity</a><ul>
<li class="chapter" data-level="12.3.1" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#activity"><i class="fa fa-check"></i><b>12.3.1</b> Activity</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#reducible-error"><i class="fa fa-check"></i><b>12.4</b> Reducible Error</a><ul>
<li class="chapter" data-level="12.4.1" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#what-is-it"><i class="fa fa-check"></i><b>12.4.1</b> What is it?</a></li>
<li class="chapter" data-level="12.4.2" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#example"><i class="fa fa-check"></i><b>12.4.2</b> Example</a></li>
<li class="chapter" data-level="12.4.3" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#bias-and-variance"><i class="fa fa-check"></i><b>12.4.3</b> Bias and Variance</a></li>
<li class="chapter" data-level="12.4.4" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#reducing-reducible-error"><i class="fa fa-check"></i><b>12.4.4</b> Reducing reducible error</a></li>
<li class="chapter" data-level="12.4.5" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#error-decomposition"><i class="fa fa-check"></i><b>12.4.5</b> Error decomposition</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#model-selection"><i class="fa fa-check"></i><b>12.5</b> Model Selection</a><ul>
<li class="chapter" data-level="12.5.1" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#exercise-cv"><i class="fa fa-check"></i><b>12.5.1</b> Exercise: CV</a></li>
<li class="chapter" data-level="12.5.2" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#out-of-sample-error"><i class="fa fa-check"></i><b>12.5.2</b> Out-of-sample Error</a></li>
<li class="chapter" data-level="12.5.3" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#alternative-measures-of-model-goodness"><i class="fa fa-check"></i><b>12.5.3</b> Alternative measures of model goodness</a></li>
<li class="chapter" data-level="12.5.4" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#feature-and-model-selection-setup"><i class="fa fa-check"></i><b>12.5.4</b> Feature and model selection: setup</a></li>
<li class="chapter" data-level="12.5.5" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#model-selection-1"><i class="fa fa-check"></i><b>12.5.5</b> Model selection</a></li>
<li class="chapter" data-level="12.5.6" data-path="overfitting-the-problem-with-adding-too-many-parameters.html"><a href="overfitting-the-problem-with-adding-too-many-parameters.html#feature-predictor-selection"><i class="fa fa-check"></i><b>12.5.6</b> Feature (predictor) selection</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="describing-relationships.html"><a href="describing-relationships.html"><i class="fa fa-check"></i>Describing Relationships</a></li>
<li class="chapter" data-level="13" data-path="theres-meaning-in-parameters.html"><a href="theres-meaning-in-parameters.html"><i class="fa fa-check"></i><b>13</b> There’s meaning in parameters</a><ul>
<li class="chapter" data-level="13.1" data-path="theres-meaning-in-parameters.html"><a href="theres-meaning-in-parameters.html#the-types-of-parametric-assumptions"><i class="fa fa-check"></i><b>13.1</b> The types of parametric assumptions</a><ul>
<li class="chapter" data-level="13.1.1" data-path="theres-meaning-in-parameters.html"><a href="theres-meaning-in-parameters.html#when-defining-a-model-function."><i class="fa fa-check"></i><b>13.1.1</b> 1. When defining a <strong>model function</strong>.</a></li>
<li class="chapter" data-level="13.1.2" data-path="theres-meaning-in-parameters.html"><a href="theres-meaning-in-parameters.html#when-defining-probability-distributions."><i class="fa fa-check"></i><b>13.1.2</b> 2. When defining <strong>probability distributions</strong>.</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="theres-meaning-in-parameters.html"><a href="theres-meaning-in-parameters.html#the-value-of-making-parametric-assumptions"><i class="fa fa-check"></i><b>13.2</b> The value of making parametric assumptions</a><ul>
<li class="chapter" data-level="13.2.1" data-path="theres-meaning-in-parameters.html"><a href="theres-meaning-in-parameters.html#value-1-reduced-error"><i class="fa fa-check"></i><b>13.2.1</b> Value #1: Reduced Error</a></li>
<li class="chapter" data-level="13.2.2" data-path="theres-meaning-in-parameters.html"><a href="theres-meaning-in-parameters.html#value-2-interpretation"><i class="fa fa-check"></i><b>13.2.2</b> Value #2: Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="theres-meaning-in-parameters.html"><a href="theres-meaning-in-parameters.html#anova"><i class="fa fa-check"></i><b>13.3</b> ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="the-meaning-of-interaction.html"><a href="the-meaning-of-interaction.html"><i class="fa fa-check"></i><b>14</b> The meaning of interaction</a></li>
<li class="chapter" data-level="15" data-path="scales-and-the-restricted-range-problem.html"><a href="scales-and-the-restricted-range-problem.html"><i class="fa fa-check"></i><b>15</b> Scales and the restricted range problem</a><ul>
<li class="chapter" data-level="15.1" data-path="scales-and-the-restricted-range-problem.html"><a href="scales-and-the-restricted-range-problem.html#problems"><i class="fa fa-check"></i><b>15.1</b> Problems</a></li>
<li class="chapter" data-level="15.2" data-path="scales-and-the-restricted-range-problem.html"><a href="scales-and-the-restricted-range-problem.html#solutions"><i class="fa fa-check"></i><b>15.2</b> Solutions</a><ul>
<li class="chapter" data-level="15.2.1" data-path="scales-and-the-restricted-range-problem.html"><a href="scales-and-the-restricted-range-problem.html#solution-1-transformations"><i class="fa fa-check"></i><b>15.2.1</b> Solution 1: Transformations</a></li>
<li class="chapter" data-level="15.2.2" data-path="scales-and-the-restricted-range-problem.html"><a href="scales-and-the-restricted-range-problem.html#solution-2-link-functions"><i class="fa fa-check"></i><b>15.2.2</b> Solution 2: Link Functions</a></li>
<li class="chapter" data-level="15.2.3" data-path="scales-and-the-restricted-range-problem.html"><a href="scales-and-the-restricted-range-problem.html#solution-3-scientifically-backed-functions"><i class="fa fa-check"></i><b>15.2.3</b> Solution 3: Scientifically-backed functions</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="scales-and-the-restricted-range-problem.html"><a href="scales-and-the-restricted-range-problem.html#glms-in-r"><i class="fa fa-check"></i><b>15.3</b> GLM’s in R</a><ul>
<li class="chapter" data-level="15.3.1" data-path="scales-and-the-restricted-range-problem.html"><a href="scales-and-the-restricted-range-problem.html#broomaugment"><i class="fa fa-check"></i><b>15.3.1</b> <code>broom::augment()</code></a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="scales-and-the-restricted-range-problem.html"><a href="scales-and-the-restricted-range-problem.html#options-for-logistic-regression"><i class="fa fa-check"></i><b>15.4</b> Options for Logistic Regression</a><ul>
<li class="chapter" data-level="15.4.1" data-path="scales-and-the-restricted-range-problem.html"><a href="scales-and-the-restricted-range-problem.html#models"><i class="fa fa-check"></i><b>15.4.1</b> Models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="improving-estimation-through-distributional-assumptions.html"><a href="improving-estimation-through-distributional-assumptions.html"><i class="fa fa-check"></i><b>16</b> Improving estimation through distributional assumptions</a></li>
<li class="chapter" data-level="17" data-path="when-we-only-want-interpretation-on-some-predictors.html"><a href="when-we-only-want-interpretation-on-some-predictors.html"><i class="fa fa-check"></i><b>17</b> When we only want interpretation on some predictors</a><ul>
<li class="chapter" data-level="17.1" data-path="when-we-only-want-interpretation-on-some-predictors.html"><a href="when-we-only-want-interpretation-on-some-predictors.html#non-identifiability-in-gams"><i class="fa fa-check"></i><b>17.1</b> Non-identifiability in GAMS</a><ul>
<li class="chapter" data-level="17.1.1" data-path="when-we-only-want-interpretation-on-some-predictors.html"><a href="when-we-only-want-interpretation-on-some-predictors.html#non-identifiability"><i class="fa fa-check"></i><b>17.1.1</b> Non-identifiability</a></li>
<li class="chapter" data-level="17.1.2" data-path="when-we-only-want-interpretation-on-some-predictors.html"><a href="when-we-only-want-interpretation-on-some-predictors.html#question-1b"><i class="fa fa-check"></i><b>17.1.2</b> Question 1b</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="special-cases.html"><a href="special-cases.html"><i class="fa fa-check"></i>Special cases</a></li>
<li class="chapter" data-level="18" data-path="regression-when-data-are-censored-survival-analysis.html"><a href="regression-when-data-are-censored-survival-analysis.html"><i class="fa fa-check"></i><b>18</b> Regression when data are censored: survival analysis</a></li>
<li class="chapter" data-level="19" data-path="regression-in-the-presence-of-outliers-robust-regression.html"><a href="regression-in-the-presence-of-outliers-robust-regression.html"><i class="fa fa-check"></i><b>19</b> Regression in the presence of outliers: robust regression</a><ul>
<li class="chapter" data-level="19.1" data-path="regression-in-the-presence-of-outliers-robust-regression.html"><a href="regression-in-the-presence-of-outliers-robust-regression.html#robust-regression-in-r"><i class="fa fa-check"></i><b>19.1</b> Robust Regression in R</a><ul>
<li class="chapter" data-level="19.1.1" data-path="regression-in-the-presence-of-outliers-robust-regression.html"><a href="regression-in-the-presence-of-outliers-robust-regression.html#heavy-tailed-regression"><i class="fa fa-check"></i><b>19.1.1</b> Heavy Tailed Regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="regression-in-the-presence-of-extremes-extreme-value-regression.html"><a href="regression-in-the-presence-of-extremes-extreme-value-regression.html"><i class="fa fa-check"></i><b>20</b> Regression in the presence of extremes: extreme value regression</a></li>
<li class="chapter" data-level="21" data-path="regression-when-data-are-ordinal.html"><a href="regression-when-data-are-ordinal.html"><i class="fa fa-check"></i><b>21</b> Regression when data are ordinal</a></li>
<li class="chapter" data-level="22" data-path="regression-when-data-are-missing-multiple-imputation.html"><a href="regression-when-data-are-missing-multiple-imputation.html"><i class="fa fa-check"></i><b>22</b> Regression when data are missing: multiple imputation</a><ul>
<li class="chapter" data-level="22.1" data-path="regression-when-data-are-missing-multiple-imputation.html"><a href="regression-when-data-are-missing-multiple-imputation.html#mean-imputation"><i class="fa fa-check"></i><b>22.1</b> Mean Imputation</a></li>
<li class="chapter" data-level="22.2" data-path="regression-when-data-are-missing-multiple-imputation.html"><a href="regression-when-data-are-missing-multiple-imputation.html#multiple-imputation"><i class="fa fa-check"></i><b>22.2</b> Multiple Imputation</a><ul>
<li class="chapter" data-level="22.2.1" data-path="regression-when-data-are-missing-multiple-imputation.html"><a href="regression-when-data-are-missing-multiple-imputation.html#patterns"><i class="fa fa-check"></i><b>22.2.1</b> Patterns</a></li>
<li class="chapter" data-level="22.2.2" data-path="regression-when-data-are-missing-multiple-imputation.html"><a href="regression-when-data-are-missing-multiple-imputation.html#multiple-imputation-1"><i class="fa fa-check"></i><b>22.2.2</b> Multiple Imputation</a></li>
<li class="chapter" data-level="22.2.3" data-path="regression-when-data-are-missing-multiple-imputation.html"><a href="regression-when-data-are-missing-multiple-imputation.html#pooling"><i class="fa fa-check"></i><b>22.2.3</b> Pooling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="23" data-path="regression-under-many-groups-mixed-effects-models.html"><a href="regression-under-many-groups-mixed-effects-models.html"><i class="fa fa-check"></i><b>23</b> Regression under many groups: mixed effects models</a><ul>
<li class="chapter" data-level="23.1" data-path="regression-under-many-groups-mixed-effects-models.html"><a href="regression-under-many-groups-mixed-effects-models.html#motivation-for-lme"><i class="fa fa-check"></i><b>23.1</b> Motivation for LME</a><ul>
<li class="chapter" data-level="23.1.1" data-path="regression-under-many-groups-mixed-effects-models.html"><a href="regression-under-many-groups-mixed-effects-models.html#definition"><i class="fa fa-check"></i><b>23.1.1</b> Definition</a></li>
<li class="chapter" data-level="23.1.2" data-path="regression-under-many-groups-mixed-effects-models.html"><a href="regression-under-many-groups-mixed-effects-models.html#r-tools-for-fitting"><i class="fa fa-check"></i><b>23.1.2</b> R Tools for Fitting</a></li>
</ul></li>
<li class="chapter" data-level="23.2" data-path="regression-under-many-groups-mixed-effects-models.html"><a href="regression-under-many-groups-mixed-effects-models.html#mixed-effects-models-in-r-tutorial"><i class="fa fa-check"></i><b>23.2</b> Mixed Effects Models in R: tutorial</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="regression-on-an-entire-distribution-probabilistic-forecasting.html"><a href="regression-on-an-entire-distribution-probabilistic-forecasting.html"><i class="fa fa-check"></i><b>24</b> Regression on an entire distribution: Probabilistic Forecasting</a><ul>
<li class="chapter" data-level="24.1" data-path="regression-on-an-entire-distribution-probabilistic-forecasting.html"><a href="regression-on-an-entire-distribution-probabilistic-forecasting.html#probabilistic-forecasting-what-it-is"><i class="fa fa-check"></i><b>24.1</b> Probabilistic Forecasting: What it is</a></li>
<li class="chapter" data-level="24.2" data-path="regression-on-an-entire-distribution-probabilistic-forecasting.html"><a href="regression-on-an-entire-distribution-probabilistic-forecasting.html#review-univariate-distribution-estimates"><i class="fa fa-check"></i><b>24.2</b> Review: Univariate distribution estimates</a><ul>
<li class="chapter" data-level="24.2.1" data-path="regression-on-an-entire-distribution-probabilistic-forecasting.html"><a href="regression-on-an-entire-distribution-probabilistic-forecasting.html#continuous-response"><i class="fa fa-check"></i><b>24.2.1</b> Continuous response</a></li>
<li class="chapter" data-level="24.2.2" data-path="regression-on-an-entire-distribution-probabilistic-forecasting.html"><a href="regression-on-an-entire-distribution-probabilistic-forecasting.html#discrete-response"><i class="fa fa-check"></i><b>24.2.2</b> Discrete Response</a></li>
</ul></li>
<li class="chapter" data-level="24.3" data-path="regression-on-an-entire-distribution-probabilistic-forecasting.html"><a href="regression-on-an-entire-distribution-probabilistic-forecasting.html#probabilistic-forecasts-subset-based-learning-methods"><i class="fa fa-check"></i><b>24.3</b> Probabilistic Forecasts: subset-based learning methods</a><ul>
<li class="chapter" data-level="24.3.1" data-path="regression-on-an-entire-distribution-probabilistic-forecasting.html"><a href="regression-on-an-entire-distribution-probabilistic-forecasting.html#the-techniques"><i class="fa fa-check"></i><b>24.3.1</b> The techniques</a></li>
<li class="chapter" data-level="24.3.2" data-path="regression-on-an-entire-distribution-probabilistic-forecasting.html"><a href="regression-on-an-entire-distribution-probabilistic-forecasting.html#exercise-1"><i class="fa fa-check"></i><b>24.3.2</b> Exercise</a></li>
<li class="chapter" data-level="24.3.3" data-path="regression-on-an-entire-distribution-probabilistic-forecasting.html"><a href="regression-on-an-entire-distribution-probabilistic-forecasting.html#bias-variance-tradeoff"><i class="fa fa-check"></i><b>24.3.3</b> Bias-variance tradeoff</a></li>
<li class="chapter" data-level="24.3.4" data-path="regression-on-an-entire-distribution-probabilistic-forecasting.html"><a href="regression-on-an-entire-distribution-probabilistic-forecasting.html#evaluating-model-goodness"><i class="fa fa-check"></i><b>24.3.4</b> Evaluating Model Goodness</a></li>
</ul></li>
<li class="chapter" data-level="24.4" data-path="regression-on-an-entire-distribution-probabilistic-forecasting.html"><a href="regression-on-an-entire-distribution-probabilistic-forecasting.html#discussion-points"><i class="fa fa-check"></i><b>24.4</b> Discussion Points</a></li>
<li class="chapter" data-level="24.5" data-path="regression-on-an-entire-distribution-probabilistic-forecasting.html"><a href="regression-on-an-entire-distribution-probabilistic-forecasting.html#when-are-they-not-useful"><i class="fa fa-check"></i><b>24.5</b> When are they not useful?</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html"><i class="fa fa-check"></i><b>25</b> Regression when order matters: time series and spatial analysis</a><ul>
<li class="chapter" data-level="25.1" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#timeseries-in-base-r"><i class="fa fa-check"></i><b>25.1</b> Timeseries in (base) R</a></li>
<li class="chapter" data-level="25.2" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#spatial-example"><i class="fa fa-check"></i><b>25.2</b> Spatial Example</a></li>
<li class="chapter" data-level="25.3" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#a-model-for-river-rock-size"><i class="fa fa-check"></i><b>25.3</b> A Model for River Rock Size</a><ul>
<li class="chapter" data-level="25.3.1" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#average-rock-size"><i class="fa fa-check"></i><b>25.3.1</b> 1. Average rock size:</a></li>
<li class="chapter" data-level="25.3.2" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#mean-rock-size"><i class="fa fa-check"></i><b>25.3.2</b> 2. Mean rock size:</a></li>
<li class="chapter" data-level="25.3.3" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#downstream-fining-curve"><i class="fa fa-check"></i><b>25.3.3</b> 3. Downstream fining curve:</a></li>
</ul></li>
<li class="chapter" data-level="25.4" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#statistical-objectives"><i class="fa fa-check"></i><b>25.4</b> Statistical Objectives</a><ul>
<li class="chapter" data-level="25.4.1" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#preliminaries-variance-and-correlation"><i class="fa fa-check"></i><b>25.4.1</b> Preliminaries: Variance and Correlation</a></li>
</ul></li>
<li class="chapter" data-level="25.5" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#three-concepts"><i class="fa fa-check"></i><b>25.5</b> Three Concepts</a><ul>
<li class="chapter" data-level="25.5.1" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#error-variance-sigma_e2leftxright"><i class="fa fa-check"></i><b>25.5.1</b> Error Variance <span class="math inline">\(\sigma_{E}^{2}\left(x\right)\)</span></a></li>
<li class="chapter" data-level="25.5.2" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#mean-variance-sigma_m2"><i class="fa fa-check"></i><b>25.5.2</b> Mean Variance <span class="math inline">\(\sigma_{M}^{2}\)</span></a></li>
<li class="chapter" data-level="25.5.3" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#mean-correlation-rholeftdright"><i class="fa fa-check"></i><b>25.5.3</b> Mean Correlation <span class="math inline">\(\rho\left(d\right)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="25.6" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#estimation-1"><i class="fa fa-check"></i><b>25.6</b> Estimation</a><ul>
<li class="chapter" data-level="25.6.1" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#constant-error-variance"><i class="fa fa-check"></i><b>25.6.1</b> Constant Error Variance</a></li>
<li class="chapter" data-level="25.6.2" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#non-constant-error-variance"><i class="fa fa-check"></i><b>25.6.2</b> Non-Constant Error Variance</a></li>
</ul></li>
<li class="chapter" data-level="25.7" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#statistical-objective-1-downstream-fining-curve"><i class="fa fa-check"></i><b>25.7</b> Statistical Objective 1: Downstream Fining Curve</a><ul>
<li class="chapter" data-level="25.7.1" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#regression-form"><i class="fa fa-check"></i><b>25.7.1</b> Regression Form</a></li>
</ul></li>
<li class="chapter" data-level="25.8" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#statistical-objective-2-river-profile"><i class="fa fa-check"></i><b>25.8</b> Statistical Objective 2: River Profile</a><ul>
<li class="chapter" data-level="25.8.1" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#simple-kriging"><i class="fa fa-check"></i><b>25.8.1</b> Simple Kriging</a></li>
<li class="chapter" data-level="25.8.2" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#universal-kriging"><i class="fa fa-check"></i><b>25.8.2</b> Universal Kriging</a></li>
<li class="chapter" data-level="25.8.3" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#kriging-under-non-constant-error-variance"><i class="fa fa-check"></i><b>25.8.3</b> Kriging under Non-Constant Error Variance</a></li>
</ul></li>
<li class="chapter" data-level="25.9" data-path="regression-when-order-matters-time-series-and-spatial-analysis.html"><a href="regression-when-order-matters-time-series-and-spatial-analysis.html#confidence-intervals-of-the-river-profile"><i class="fa fa-check"></i><b>25.9</b> Confidence Intervals of the River Profile</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/vincenzocoia/Interpreting-Regression" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpreting Regression</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression-when-data-are-missing-multiple-imputation" class="section level1">
<h1><span class="header-section-number">Chapter 22</span> Regression when data are missing: multiple imputation</h1>
<p><strong>Caution: in a highly developmental stage! See Section <a href="index.html#caution">1.1</a>.</strong></p>
<p>(DSCI 562 Tutorial)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">suppressPackageStartupMessages</span>(<span class="kw">library</span>(tidyverse))</code></pre></div>
<pre><code>## Warning: package &#39;ggplot2&#39; was built under R version 3.5.2</code></pre>
<pre><code>## Warning: package &#39;tibble&#39; was built under R version 3.5.2</code></pre>
<pre><code>## Warning: package &#39;purrr&#39; was built under R version 3.5.2</code></pre>
<pre><code>## Warning: package &#39;dplyr&#39; was built under R version 3.5.2</code></pre>
<pre><code>## Warning: package &#39;stringr&#39; was built under R version 3.5.2</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">suppressPackageStartupMessages</span>(<span class="kw">library</span>(mice))</code></pre></div>
<p>Let’s take a closer look at mean imputation vs. multiple imputation.</p>
<div id="mean-imputation" class="section level2">
<h2><span class="header-section-number">22.1</span> Mean Imputation</h2>
<p>Let’s consider a simple linear regression example, with one explanatory variable. We’ll generate 100 data points, and make 10 of the response values missing.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">13</span>)
x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>)
y &lt;-<span class="st"> </span>-<span class="dv">1</span> +<span class="st"> </span><span class="dv">2</span> *<span class="st"> </span>x +<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>)
y[<span class="dv">1</span>:<span class="dv">10</span>] &lt;-<span class="st"> </span><span class="ot">NA</span></code></pre></div>
<p>Here are the data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">x</code></pre></div>
<pre><code>##   [1]  0.55432694 -0.28027194  1.77516337  0.18732012  1.14252615
##   [6]  0.41552613  1.22950656  0.23667967 -0.36538277  1.10514427
##  [11] -1.09359397  0.46187091 -1.36098453 -1.85602715 -0.43985541
##  [16] -0.19394690  1.39643151  0.10066325 -0.11443881  0.70222523
##  [21]  0.26254267  1.83616330  0.35740242 -1.04541013  0.62018413
##  [26]  0.14935453 -1.45931685 -2.02704380 -1.05695776 -0.72814372
##  [31] -0.00821067  0.84779738 -0.38349150 -0.52651151 -0.27322596
##  [36] -0.60574161 -0.33286731 -0.24153755 -0.86277540 -0.84697075
##  [41]  0.10034035  1.59003353  0.56649488  1.61447949 -0.46865016
##  [46] -0.72610140 -1.02333900 -1.93781553  0.27714729  1.40835367
##  [51]  0.27312919  0.75552507 -0.34901841 -0.54619076  0.23436199
##  [56] -0.29782822 -0.84047613  0.82651036  1.48369123  0.69967564
##  [61] -1.26157415  0.29827174 -0.14780711 -0.88892233  1.01306586
##  [66] -0.92052508 -0.57389450  1.15036548  1.14382456 -0.23944276
##  [71] -1.08680215 -0.06144699 -0.51669734 -1.90767369  0.10715648
##  [76] -1.17737519  1.74542691 -0.39869853  0.44243942  0.45027946
##  [81] -0.07606216  0.29751322 -1.19435471 -1.99687548  1.38851305
##  [86] -0.08248357  0.39251449 -1.08276971  1.60212039  1.00406897
##  [91]  0.37989570 -0.56550536 -1.21377810 -1.36430159 -1.41613295
##  [96] -0.25557803 -1.22542595  0.21383426  0.06722356  0.85663511</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">y</code></pre></div>
<pre><code>##   [1]           NA           NA           NA           NA           NA
##   [6]           NA           NA           NA           NA           NA
##  [11] -4.053704654  1.559887706 -4.743071625 -5.523818780 -1.930473677
##  [16] -1.500485206  2.645513317 -0.051326812 -0.839409352  0.218430884
##  [21]  0.850566209  3.126514212 -0.368543711 -3.162228622 -1.105128040
##  [26] -0.902167648 -4.154972172 -5.111932100 -4.145855361 -3.322836591
##  [31] -0.168810384  0.819016643 -1.365461091 -1.130697319  0.240141538
##  [36] -2.390779077 -2.058218000 -0.761012345 -1.767026541 -3.989408584
##  [41] -0.459957593  1.032304370 -0.957928133  0.235330176 -1.507042163
##  [46] -0.745023600 -4.628929629 -5.232634575 -2.144358973  0.664736992
##  [51] -3.298505466  2.225627728 -2.926853644 -2.406454479 -0.601188334
##  [56] -2.433257875 -2.434091710 -1.922107514  1.971684397  2.745313865
##  [61] -3.459211491  0.705772270 -1.719688562 -2.123423177  1.619808115
##  [66] -3.826059870 -1.864032144  1.330204157  2.087342480 -2.782158129
##  [71] -0.403227138 -1.468562228 -1.026899366 -2.000743246  0.042009453
##  [76] -0.473418979  2.841051621 -2.703355211  0.700489075 -0.592450346
##  [81] -1.683073694  0.229914942 -5.462264420 -5.187776409  1.969480413
##  [86] -2.450285233 -0.005289845 -3.465216049  1.160366954  1.827202816
##  [91]  0.761346358 -1.696197511 -2.962489498 -4.827255075 -3.221340010
##  [96] -1.494866659 -2.714534509  0.673879626 -1.598181064  0.641959448</code></pre>
<p>Here’s the scatterplot with the missing data removed, and the corresponding linear regression fit:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">p &lt;-<span class="st"> </span><span class="kw">qplot</span>(x, y) +<span class="st"> </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>)
p</code></pre></div>
<pre><code>## Warning: Removed 10 rows containing non-finite values (stat_smooth).</code></pre>
<pre><code>## Warning: Removed 10 rows containing missing values (geom_point).</code></pre>
<p><img src="200-Regression_when_data_are_missing_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>The mean imputation method replaces the <code>NA</code>’s with an estimate for the mean of <span class="math inline">\(Y\)</span>. The simplest case is to use the sample average of the response. The imputed observations are shown in red, and the resulting <code>lm</code> fit is also in red.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ybar &lt;-<span class="st"> </span><span class="kw">mean</span>(y, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)
datrm &lt;-<span class="st"> </span><span class="kw">na.omit</span>(<span class="kw">data.frame</span>(<span class="dt">x=</span>x, <span class="dt">y=</span>y))
datimp &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x=</span>x[<span class="dv">1</span>:<span class="dv">10</span>], <span class="dt">y=</span>ybar)
p +<span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">data=</span>datimp, <span class="dt">colour=</span><span class="st">&quot;red&quot;</span>) +
<span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">data=</span><span class="kw">rbind</span>(datrm, datimp), <span class="dt">method=</span><span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>, <span class="dt">colour=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<pre><code>## Warning: Removed 10 rows containing non-finite values (stat_smooth).</code></pre>
<pre><code>## Warning: Removed 10 rows containing missing values (geom_point).</code></pre>
<p><img src="200-Regression_when_data_are_missing_files/figure-html/unnamed-chunk-5-1.png" width="672" /></p>
<p>Notice that the new regression line is flatter.</p>
<p>Another mean-imputation method is to replace the <code>NA</code>’s with an alternative mean estimate: the regression predictions.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit2 &lt;-<span class="st"> </span><span class="kw">lm</span>(y ~<span class="st"> </span>x, <span class="dt">na.action=</span>na.omit)
yhat &lt;-<span class="st"> </span><span class="kw">predict</span>(fit2, <span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">x=</span>x[<span class="dv">1</span>:<span class="dv">10</span>]))
datimp2 &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x=</span>x[<span class="dv">1</span>:<span class="dv">10</span>], <span class="dt">y=</span>yhat)
p +<span class="st"> </span><span class="kw">geom_point</span>(<span class="dt">data=</span>datimp2, <span class="dt">colour=</span><span class="st">&quot;red&quot;</span>) +
<span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">data=</span><span class="kw">rbind</span>(datrm, datimp2), <span class="dt">method=</span><span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>, <span class="dt">colour=</span><span class="st">&quot;red&quot;</span>, <span class="dt">size=</span><span class="fl">0.5</span>)</code></pre></div>
<pre><code>## Warning: Removed 10 rows containing non-finite values (stat_smooth).</code></pre>
<pre><code>## Warning: Removed 10 rows containing missing values (geom_point).</code></pre>
<p><img src="200-Regression_when_data_are_missing_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>The regression line has not changed. This method seems smarter, but it still has consequences, since the imputed data suggests that the dataset is bound closer to the regression line than reality. So the residual variance is biased to be smaller.</p>
<p>These are both mean imputation methods. So, in your Lab 2 assignment, you can use any mean imputation method – your explanation of the comparison will just depend on what you choose.</p>
</div>
<div id="multiple-imputation" class="section level2">
<h2><span class="header-section-number">22.2</span> Multiple Imputation</h2>
<p>Recall that <em>multiple imputation</em> is a technique for handling missing data. It replaces the missing data with <em>many</em> plausible values, to obtain mutliple data sets. An analysis is done on each data set, and the results are combined.</p>
<p>A very powerful R package to assist with multiple imputation is the <code>mice</code> package. Some key things that it does:</p>
<ul>
<li>Displays patterns in missing data.</li>
<li>Imputes data to obtain multiple data sets.</li>
<li>Pools multiple analyses into one.</li>
</ul>
<p>We’ll look at the <code>airquality</code> dataset in R.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(airquality)</code></pre></div>
<pre><code>##   Ozone Solar.R Wind Temp Month Day
## 1    41     190  7.4   67     5   1
## 2    36     118  8.0   72     5   2
## 3    12     149 12.6   74     5   3
## 4    18     313 11.5   62     5   4
## 5    NA      NA 14.3   56     5   5
## 6    28      NA 14.9   66     5   6</code></pre>
<div id="patterns" class="section level3">
<h3><span class="header-section-number">22.2.1</span> Patterns</h3>
<p>Where are the <code>NA</code>s?</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">md.pattern</span>(airquality)</code></pre></div>
<p><img src="200-Regression_when_data_are_missing_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<pre><code>##     Wind Temp Month Day Solar.R Ozone   
## 111    1    1     1   1       1     1  0
## 35     1    1     1   1       1     0  1
## 5      1    1     1   1       0     1  1
## 2      1    1     1   1       0     0  2
##        0    0     0   0       7    37 44</code></pre>
<p>A “1” indicates that an observation is present, and a “0” indicates absense. The periphery of the matrix are counts: to the right, are the number of <code>NA</code>s in the row; at the bottom, are the number of <code>NA</code>s in each column; to the left, are the number of observations having a missing data pattern indicated in the matrix.</p>
<p>So we can see that there are 7 missing Solar Radiation observations, and 37 missing Ozone observations. We could check that in another way as follows:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="kw">is.na</span>(airquality$Solar.R))</code></pre></div>
<pre><code>## [1] 7</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sum</span>(<span class="kw">is.na</span>(airquality$Ozone))</code></pre></div>
<pre><code>## [1] 37</code></pre>
</div>
<div id="multiple-imputation-1" class="section level3">
<h3><span class="header-section-number">22.2.2</span> Multiple Imputation</h3>
<p>There are many methods of doing an imputation. But generally, they use other columns in the data set to do prediction on the missing data.</p>
<p>The function to do this is <code>mice</code>. Let’s impute 50 data sets using the “Predictive Mean Matching” method.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(dats &lt;-<span class="st"> </span><span class="kw">mice</span>(airquality, <span class="dt">m=</span><span class="dv">50</span>, <span class="dt">method=</span><span class="st">&quot;pmm&quot;</span>, <span class="dt">seed=</span><span class="dv">123</span>, <span class="dt">printFlag=</span><span class="ot">FALSE</span>))</code></pre></div>
<pre><code>## Class: mids
## Number of multiple imputations:  50 
## Imputation methods:
##   Ozone Solar.R    Wind    Temp   Month     Day 
##   &quot;pmm&quot;   &quot;pmm&quot;      &quot;&quot;      &quot;&quot;      &quot;&quot;      &quot;&quot; 
## PredictorMatrix:
##         Ozone Solar.R Wind Temp Month Day
## Ozone       0       1    1    1     1   1
## Solar.R     1       0    1    1     1   1
## Wind        1       1    0    1     1   1
## Temp        1       1    1    0     1   1
## Month       1       1    1    1     0   1
## Day         1       1    1    1     1   0</code></pre>
<p>The <code>m</code> argument is the number of imputed datasets. <code>method</code> is the method (you can check out the other methods in the “Details” part of the documentation of <code>mice</code>). Because there’s a random component to the imputation, <code>seed</code> indicates the seed to initiate the random number generator – useful for reproducibility! Finally, I didn’t want <code>mice</code> to be verbose with its output, so I silenced it with <code>printFlag=FALSE</code>.</p>
<p><code>dats</code> isn’t just a list of 50 datasets. It has more information bundled in it. The info is bundled in an object of type “mids”:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">class</span>(dats)</code></pre></div>
<pre><code>## [1] &quot;mids&quot;</code></pre>
<p>But we can extract the data sets. Want to see the fourth imputed data set? Here it is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">head</span>(mice::<span class="kw">complete</span>(dats, <span class="dv">4</span>))</code></pre></div>
<pre><code>##   Ozone Solar.R Wind Temp Month Day
## 1    41     190  7.4   67     5   1
## 2    36     118  8.0   72     5   2
## 3    12     149 12.6   74     5   3
## 4    18     313 11.5   62     5   4
## 5     8     127 14.3   56     5   5
## 6    28     314 14.9   66     5   6</code></pre>
</div>
<div id="pooling" class="section level3">
<h3><span class="header-section-number">22.2.3</span> Pooling</h3>
<p>The <code>mice</code> package allows you to pool many types of regression analyses. Let’s try a simple linear regression to predict <code>Ozone</code> from <code>Solar.R</code>, <code>Wind</code>, and <code>Temp</code>. You’ll need to use base R’s <code>with</code> function.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fits &lt;-<span class="st"> </span><span class="kw">with</span>(dats, <span class="kw">lm</span>(Ozone ~<span class="st"> </span>Solar.R +<span class="st"> </span>Wind +<span class="st"> </span>Temp))</code></pre></div>
<p>If you were to print <code>fits</code> to the screen, it would look like a list of 50 regression fits – one for each of the imputed data sets. But it’s not. Take a look:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">names</span>(fits)</code></pre></div>
<pre><code>## [1] &quot;call&quot;     &quot;call1&quot;    &quot;nmis&quot;     &quot;analyses&quot;</code></pre>
<p>Like <code>dats</code>, <code>fits</code> has more info in it. But it <em>does</em> have the 50 regression fits. And they can be pooled using the <code>pool</code> function:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(fit &lt;-<span class="st"> </span><span class="kw">pool</span>(fits))</code></pre></div>
<pre><code>## Class: mipo    m = 50 
##                 estimate         ubar            b            t dfcom
## (Intercept) -61.90301171 3.811506e+02 1.307680e+02 5.145339e+02   149
## Solar.R       0.05910719 4.108874e-04 1.037848e-04 5.167480e-04   149
## Wind         -3.11988214 3.146474e-01 1.181007e-01 4.351101e-01   149
## Temp          1.59210031 4.685921e-02 1.183499e-02 5.893090e-02   149
##                    df       riv    lambda       fmi
## (Intercept)  94.76599 0.3499492 0.2592314 0.2743853
## Solar.R     106.27508 0.2576387 0.2048591 0.2194121
## Wind         91.16698 0.3828499 0.2768557 0.2922145
## Temp        106.27817 0.2576162 0.2048448 0.2193977</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(fit)</code></pre></div>
<pre><code>##                 estimate   std.error statistic        df      p.value
## (Intercept) -61.90301171 22.68334009 -2.729008  94.76599 7.435912e-03
## Solar.R       0.05910719  0.02273209  2.600165 106.27508 1.064336e-02
## Wind         -3.11988214  0.65962874 -4.729755  91.16698 6.945757e-06
## Temp          1.59210031  0.24275688  6.558415 106.27817 2.021784e-09</code></pre>
<p>And there are the results of the pooled fit. This pooling works for more than just <code>lm</code>!</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression-when-data-are-ordinal.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regression-under-many-groups-mixed-effects-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/vincenzocoia/Interpreting-Regression/edit/master/200-Regression_when_data_are_missing.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["Interpreting-Regression.pdf", "Interpreting-Regression.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
