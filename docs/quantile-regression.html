<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Chapter 6 Quantile Regression | Interpreting Regression</title>
  <meta name="description" content="My tutorials for regression analysis, in the form of a bookdown book.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Chapter 6 Quantile Regression | Interpreting Regression" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="My tutorials for regression analysis, in the form of a bookdown book." />
  <meta name="github-repo" content="vincenzocoia/Interpreting-Regression" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 6 Quantile Regression | Interpreting Regression" />
  
  <meta name="twitter:description" content="My tutorials for regression analysis, in the form of a bookdown book." />
  

<meta name="author" content="Vincenzo Coia">


<meta name="date" content="2019-03-05">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="probabilistic-forecasting.html">
<link rel="next" href="introduction-to-machine-learning.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Interpreting Regression</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preamble</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#caution"><i class="fa fa-check"></i><b>1.1</b> Caution</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#purpose-of-the-book"><i class="fa fa-check"></i><b>1.2</b> Purpose of the book</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#tasks-that-motivate-regression"><i class="fa fa-check"></i><b>1.3</b> Tasks that motivate Regression</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="distributions.html"><a href="distributions.html"><i class="fa fa-check"></i><b>2</b> Distributions</a><ul>
<li class="chapter" data-level="2.1" data-path="distributions.html"><a href="distributions.html#probabilistic-quantities"><i class="fa fa-check"></i><b>2.1</b> Probabilistic Quantities</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="estimation.html"><a href="estimation.html"><i class="fa fa-check"></i><b>3</b> Estimation</a><ul>
<li class="chapter" data-level="3.1" data-path="estimation.html"><a href="estimation.html#estimation-of-probabilistic-quantities"><i class="fa fa-check"></i><b>3.1</b> Estimation of Probabilistic Quantities</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="writing-the-sample-mean-as-an-optimization-problem.html"><a href="writing-the-sample-mean-as-an-optimization-problem.html"><i class="fa fa-check"></i><b>4</b> Writing the sample mean as an optimization problem</a></li>
<li class="chapter" data-level="5" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html"><i class="fa fa-check"></i><b>5</b> Probabilistic Forecasting</a><ul>
<li class="chapter" data-level="5.1" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#probabilistic-forecasting-what-it-is"><i class="fa fa-check"></i><b>5.1</b> Probabilistic Forecasting: What it is</a></li>
<li class="chapter" data-level="5.2" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#review-univariate-distribution-estimates"><i class="fa fa-check"></i><b>5.2</b> Review: Univariate distribution estimates</a><ul>
<li class="chapter" data-level="5.2.1" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#continuous-response"><i class="fa fa-check"></i><b>5.2.1</b> Continuous response</a></li>
<li class="chapter" data-level="5.2.2" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#discrete-response"><i class="fa fa-check"></i><b>5.2.2</b> Discrete Response</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#probabilistic-forecasts-subset-based-learning-methods"><i class="fa fa-check"></i><b>5.3</b> Probabilistic Forecasts: subset-based learning methods</a><ul>
<li class="chapter" data-level="5.3.1" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#the-techniques"><i class="fa fa-check"></i><b>5.3.1</b> The techniques</a></li>
<li class="chapter" data-level="5.3.2" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#exercise"><i class="fa fa-check"></i><b>5.3.2</b> Exercise</a></li>
<li class="chapter" data-level="5.3.3" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#bias-variance-tradeoff"><i class="fa fa-check"></i><b>5.3.3</b> Bias-variance tradeoff</a></li>
<li class="chapter" data-level="5.3.4" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#evaluating-model-goodness"><i class="fa fa-check"></i><b>5.3.4</b> Evaluating Model Goodness</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#discussion-points"><i class="fa fa-check"></i><b>5.4</b> Discussion Points</a></li>
<li class="chapter" data-level="5.5" data-path="probabilistic-forecasting.html"><a href="probabilistic-forecasting.html#when-are-they-not-useful"><i class="fa fa-check"></i><b>5.5</b> When are they not useful?</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="quantile-regression.html"><a href="quantile-regression.html"><i class="fa fa-check"></i><b>6</b> Quantile Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="quantile-regression.html"><a href="quantile-regression.html#what-is-the-mean-anyway"><i class="fa fa-check"></i><b>6.1</b> What is the mean, anyway?</a></li>
<li class="chapter" data-level="6.2" data-path="quantile-regression.html"><a href="quantile-regression.html#linear-quantile-regression"><i class="fa fa-check"></i><b>6.2</b> Linear Quantile Regression</a></li>
<li class="chapter" data-level="6.3" data-path="quantile-regression.html"><a href="quantile-regression.html#exercise-1"><i class="fa fa-check"></i><b>6.3</b> Exercise</a></li>
<li class="chapter" data-level="6.4" data-path="quantile-regression.html"><a href="quantile-regression.html#problem-crossing-quantiles"><i class="fa fa-check"></i><b>6.4</b> Problem: Crossing quantiles</a></li>
<li class="chapter" data-level="6.5" data-path="quantile-regression.html"><a href="quantile-regression.html#problem-upper-quantiles"><i class="fa fa-check"></i><b>6.5</b> Problem: Upper quantiles</a></li>
<li class="chapter" data-level="6.6" data-path="quantile-regression.html"><a href="quantile-regression.html#evaluating-model-goodness-1"><i class="fa fa-check"></i><b>6.6</b> Evaluating Model Goodness</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html"><i class="fa fa-check"></i><b>7</b> Introduction to Machine Learning</a><ul>
<li class="chapter" data-level="7.1" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#what-machine-learning-is"><i class="fa fa-check"></i><b>7.1</b> What machine learning is</a></li>
<li class="chapter" data-level="7.2" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#variable-terminology"><i class="fa fa-check"></i><b>7.2</b> Variable terminology</a><ul>
<li class="chapter" data-level="7.2.1" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#variable-types"><i class="fa fa-check"></i><b>7.2.1</b> Variable types</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#types-of-supervised-learning"><i class="fa fa-check"></i><b>7.3</b> Types of Supervised Learning</a></li>
<li class="chapter" data-level="7.4" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#together-linear-regression-example"><i class="fa fa-check"></i><b>7.4</b> Together: Linear Regression Example</a></li>
<li class="chapter" data-level="7.5" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#irreducible-error"><i class="fa fa-check"></i><b>7.5</b> Irreducible Error</a></li>
<li class="chapter" data-level="7.6" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#in-class-exercises-irreducible-error"><i class="fa fa-check"></i><b>7.6</b> In-class Exercises: Irreducible Error</a><ul>
<li class="chapter" data-level="7.6.1" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#oracle-regression"><i class="fa fa-check"></i><b>7.6.1</b> Oracle regression</a></li>
<li class="chapter" data-level="7.6.2" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#oracle-classification"><i class="fa fa-check"></i><b>7.6.2</b> Oracle classification</a></li>
<li class="chapter" data-level="7.6.3" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#bonus-random-prediction"><i class="fa fa-check"></i><b>7.6.3</b> (BONUS) Random prediction</a></li>
<li class="chapter" data-level="7.6.4" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#bonus-a-more-non-standard-regression"><i class="fa fa-check"></i><b>7.6.4</b> (BONUS) A more non-standard regression</a></li>
<li class="chapter" data-level="7.6.5" data-path="introduction-to-machine-learning.html"><a href="introduction-to-machine-learning.html#bonus-oracle-mse"><i class="fa fa-check"></i><b>7.6.5</b> (BONUS) Oracle MSE</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html"><i class="fa fa-check"></i><b>8</b> Regression in the context of problem solving</a><ul>
<li class="chapter" data-level="8.1" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#communicating-distillation-3-4"><i class="fa fa-check"></i><b>8.1</b> Communicating (Distillation 3-4)</a></li>
<li class="chapter" data-level="8.2" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#modelling-distillation-2-3"><i class="fa fa-check"></i><b>8.2</b> Modelling (Distillation 2-3)</a></li>
<li class="chapter" data-level="8.3" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#asking-useful-statistical-questions-distillation-1-2"><i class="fa fa-check"></i><b>8.3</b> Asking useful statistical questions (Distillation 1-2)</a><ul>
<li class="chapter" data-level="8.3.1" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#business-objectives-examples"><i class="fa fa-check"></i><b>8.3.1</b> Business objectives: examples</a></li>
<li class="chapter" data-level="8.3.2" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#statistical-objectives-refining"><i class="fa fa-check"></i><b>8.3.2</b> Statistical objectives: refining</a></li>
<li class="chapter" data-level="8.3.3" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#statistical-objectives-examples"><i class="fa fa-check"></i><b>8.3.3</b> Statistical objectives: examples</a></li>
<li class="chapter" data-level="8.3.4" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#statistical-questions-are-not-the-full-picture"><i class="fa fa-check"></i><b>8.3.4</b> Statistical questions are not the full picture</a></li>
<li class="chapter" data-level="8.3.5" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#statistical-objectives-unrelated-to-supervised-learning"><i class="fa fa-check"></i><b>8.3.5</b> Statistical objectives unrelated to supervised learning</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="regression-in-the-context-of-problem-solving.html"><a href="regression-in-the-context-of-problem-solving.html#prerequisites-to-an-analysis"><i class="fa fa-check"></i><b>8.4</b> Prerequisites to an analysis</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="local-regression.html"><a href="local-regression.html"><i class="fa fa-check"></i><b>9</b> Local Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="local-regression.html"><a href="local-regression.html#knn"><i class="fa fa-check"></i><b>9.1</b> kNN</a></li>
<li class="chapter" data-level="9.2" data-path="local-regression.html"><a href="local-regression.html#loess"><i class="fa fa-check"></i><b>9.2</b> loess</a></li>
<li class="chapter" data-level="9.3" data-path="local-regression.html"><a href="local-regression.html#in-class-exercises"><i class="fa fa-check"></i><b>9.3</b> In-Class Exercises</a><ul>
<li class="chapter" data-level="9.3.1" data-path="local-regression.html"><a href="local-regression.html#exercise-1-mean-at-x0"><i class="fa fa-check"></i><b>9.3.1</b> Exercise 1: Mean at <span class="math inline">\(X=0\)</span></a></li>
<li class="chapter" data-level="9.3.2" data-path="local-regression.html"><a href="local-regression.html#exercise-2-regression-curve"><i class="fa fa-check"></i><b>9.3.2</b> Exercise 2: Regression Curve</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="local-regression.html"><a href="local-regression.html#hyperparameters-and-the-biasvariance-tradeoff"><i class="fa fa-check"></i><b>9.4</b> Hyperparameters and the bias/variance tradeoff</a></li>
<li class="chapter" data-level="9.5" data-path="local-regression.html"><a href="local-regression.html#extensions-to-knn-and-loess"><i class="fa fa-check"></i><b>9.5</b> Extensions to kNN and loess</a><ul>
<li class="chapter" data-level="9.5.1" data-path="local-regression.html"><a href="local-regression.html#kernel-weighting"><i class="fa fa-check"></i><b>9.5.1</b> Kernel weighting</a></li>
<li class="chapter" data-level="9.5.2" data-path="local-regression.html"><a href="local-regression.html#local-polynomials"><i class="fa fa-check"></i><b>9.5.2</b> Local polynomials</a></li>
<li class="chapter" data-level="9.5.3" data-path="local-regression.html"><a href="local-regression.html#combination"><i class="fa fa-check"></i><b>9.5.3</b> Combination</a></li>
<li class="chapter" data-level="9.5.4" data-path="local-regression.html"><a href="local-regression.html#other-distances"><i class="fa fa-check"></i><b>9.5.4</b> Other distances</a></li>
<li class="chapter" data-level="9.5.5" data-path="local-regression.html"><a href="local-regression.html#scaling"><i class="fa fa-check"></i><b>9.5.5</b> Scaling</a></li>
<li class="chapter" data-level="9.5.6" data-path="local-regression.html"><a href="local-regression.html#demonstration"><i class="fa fa-check"></i><b>9.5.6</b> Demonstration</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="local-regression.html"><a href="local-regression.html#model-assumptions-and-the-biasvariance-tradeoff"><i class="fa fa-check"></i><b>9.6</b> Model assumptions and the bias/variance tradeoff</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="reducible-error.html"><a href="reducible-error.html"><i class="fa fa-check"></i><b>10</b> Reducible Error</a><ul>
<li class="chapter" data-level="10.1" data-path="reducible-error.html"><a href="reducible-error.html#classification-exercise-do-together"><i class="fa fa-check"></i><b>10.1</b> Classification Exercise: Do Together</a></li>
<li class="chapter" data-level="10.2" data-path="reducible-error.html"><a href="reducible-error.html#training-error-vs.generalization-error"><i class="fa fa-check"></i><b>10.2</b> Training Error vs. Generalization Error</a></li>
<li class="chapter" data-level="10.3" data-path="reducible-error.html"><a href="reducible-error.html#model-complexity"><i class="fa fa-check"></i><b>10.3</b> Model complexity</a><ul>
<li class="chapter" data-level="10.3.1" data-path="reducible-error.html"><a href="reducible-error.html#activity"><i class="fa fa-check"></i><b>10.3.1</b> Activity</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="reducible-error.html"><a href="reducible-error.html#reducible-error-1"><i class="fa fa-check"></i><b>10.4</b> Reducible Error</a><ul>
<li class="chapter" data-level="10.4.1" data-path="reducible-error.html"><a href="reducible-error.html#what-is-it"><i class="fa fa-check"></i><b>10.4.1</b> What is it?</a></li>
<li class="chapter" data-level="10.4.2" data-path="reducible-error.html"><a href="reducible-error.html#example"><i class="fa fa-check"></i><b>10.4.2</b> Example</a></li>
<li class="chapter" data-level="10.4.3" data-path="reducible-error.html"><a href="reducible-error.html#bias-and-variance"><i class="fa fa-check"></i><b>10.4.3</b> Bias and Variance</a></li>
<li class="chapter" data-level="10.4.4" data-path="reducible-error.html"><a href="reducible-error.html#reducing-reducible-error"><i class="fa fa-check"></i><b>10.4.4</b> Reducing reducible error</a></li>
<li class="chapter" data-level="10.4.5" data-path="reducible-error.html"><a href="reducible-error.html#error-decomposition"><i class="fa fa-check"></i><b>10.4.5</b> Error decomposition</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="model-selection.html"><a href="model-selection.html"><i class="fa fa-check"></i><b>11</b> Model Selection</a><ul>
<li class="chapter" data-level="11.1" data-path="model-selection.html"><a href="model-selection.html#exercise-cv"><i class="fa fa-check"></i><b>11.1</b> Exercise: CV</a></li>
<li class="chapter" data-level="11.2" data-path="model-selection.html"><a href="model-selection.html#out-of-sample-error"><i class="fa fa-check"></i><b>11.2</b> Out-of-sample Error</a><ul>
<li class="chapter" data-level="11.2.1" data-path="model-selection.html"><a href="model-selection.html#the-fundamental-problem"><i class="fa fa-check"></i><b>11.2.1</b> The fundamental problem</a></li>
<li class="chapter" data-level="11.2.2" data-path="model-selection.html"><a href="model-selection.html#solution-1-use-a-hold-out-set."><i class="fa fa-check"></i><b>11.2.2</b> Solution 1: Use a hold-out set.</a></li>
<li class="chapter" data-level="11.2.3" data-path="model-selection.html"><a href="model-selection.html#solution-2-cross-validation"><i class="fa fa-check"></i><b>11.2.3</b> Solution 2: Cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="model-selection.html"><a href="model-selection.html#alternative-measures-of-model-goodness"><i class="fa fa-check"></i><b>11.3</b> Alternative measures of model goodness</a></li>
<li class="chapter" data-level="11.4" data-path="model-selection.html"><a href="model-selection.html#feature-and-model-selection-setup"><i class="fa fa-check"></i><b>11.4</b> Feature and model selection: setup</a></li>
<li class="chapter" data-level="11.5" data-path="model-selection.html"><a href="model-selection.html#model-selection-1"><i class="fa fa-check"></i><b>11.5</b> Model selection</a></li>
<li class="chapter" data-level="11.6" data-path="model-selection.html"><a href="model-selection.html#feature-predictor-selection"><i class="fa fa-check"></i><b>11.6</b> Feature (predictor) selection</a><ul>
<li class="chapter" data-level="11.6.1" data-path="model-selection.html"><a href="model-selection.html#specialized-metrics-for-feature-selection"><i class="fa fa-check"></i><b>11.6.1</b> Specialized metrics for feature selection</a></li>
<li class="chapter" data-level="11.6.2" data-path="model-selection.html"><a href="model-selection.html#greedy-selection"><i class="fa fa-check"></i><b>11.6.2</b> Greedy Selection</a></li>
<li class="chapter" data-level="11.6.3" data-path="model-selection.html"><a href="model-selection.html#regularization"><i class="fa fa-check"></i><b>11.6.3</b> Regularization</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="splines-and-loess-regression.html"><a href="splines-and-loess-regression.html"><i class="fa fa-check"></i><b>12</b> Splines and Loess Regression</a><ul>
<li class="chapter" data-level="12.1" data-path="splines-and-loess-regression.html"><a href="splines-and-loess-regression.html#loess-1"><i class="fa fa-check"></i><b>12.1</b> Loess</a><ul>
<li class="chapter" data-level="12.1.1" data-path="splines-and-loess-regression.html"><a href="splines-and-loess-regression.html#the-moving-window"><i class="fa fa-check"></i><b>12.1.1</b> The “Moving Window”</a></li>
<li class="chapter" data-level="12.1.2" data-path="splines-and-loess-regression.html"><a href="splines-and-loess-regression.html#ggplot2"><i class="fa fa-check"></i><b>12.1.2</b> <code>ggplot2</code></a></li>
<li class="chapter" data-level="12.1.3" data-path="splines-and-loess-regression.html"><a href="splines-and-loess-regression.html#manual-method"><i class="fa fa-check"></i><b>12.1.3</b> Manual method</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="model-fitting-in-r.html"><a href="model-fitting-in-r.html"><i class="fa fa-check"></i><b>13</b> Model fitting in R</a><ul>
<li class="chapter" data-level="13.1" data-path="model-fitting-in-r.html"><a href="model-fitting-in-r.html#broom-package"><i class="fa fa-check"></i><b>13.1</b> <code>broom</code> package</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>14</b> Simple Linear Regression</a><ul>
<li class="chapter" data-level="14.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#model-specification"><i class="fa fa-check"></i><b>14.1</b> Model Specification</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="linear-models-in-general.html"><a href="linear-models-in-general.html"><i class="fa fa-check"></i><b>15</b> Linear models in general</a></li>
<li class="chapter" data-level="16" data-path="reference-treatment-parameterization.html"><a href="reference-treatment-parameterization.html"><i class="fa fa-check"></i><b>16</b> reference-treatment parameterization</a><ul>
<li class="chapter" data-level="16.1" data-path="reference-treatment-parameterization.html"><a href="reference-treatment-parameterization.html#more-than-one-category-lab-2"><i class="fa fa-check"></i><b>16.1</b> More than one category (Lab 2)</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="non-identifiability-in-gams.html"><a href="non-identifiability-in-gams.html"><i class="fa fa-check"></i><b>17</b> Non-identifiability in GAMS</a><ul>
<li class="chapter" data-level="17.1" data-path="non-identifiability-in-gams.html"><a href="non-identifiability-in-gams.html#non-identifiability"><i class="fa fa-check"></i><b>17.1</b> Non-identifiability</a></li>
<li class="chapter" data-level="17.2" data-path="non-identifiability-in-gams.html"><a href="non-identifiability-in-gams.html#question-1b"><i class="fa fa-check"></i><b>17.2</b> Question 1b</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>18</b> ANOVA</a><ul>
<li class="chapter" data-level="18.1" data-path="anova.html"><a href="anova.html#the-types-of-parametric-assumptions"><i class="fa fa-check"></i><b>18.1</b> The types of parametric assumptions</a><ul>
<li class="chapter" data-level="18.1.1" data-path="anova.html"><a href="anova.html#when-defining-a-model-function."><i class="fa fa-check"></i><b>18.1.1</b> 1. When defining a <strong>model function</strong>.</a></li>
<li class="chapter" data-level="18.1.2" data-path="anova.html"><a href="anova.html#when-defining-probability-distributions."><i class="fa fa-check"></i><b>18.1.2</b> 2. When defining <strong>probability distributions</strong>.</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="anova.html"><a href="anova.html#the-value-of-making-parametric-assumptions"><i class="fa fa-check"></i><b>18.2</b> The value of making parametric assumptions</a><ul>
<li class="chapter" data-level="18.2.1" data-path="anova.html"><a href="anova.html#value-1-reduced-error"><i class="fa fa-check"></i><b>18.2.1</b> Value #1: Reduced Error</a></li>
<li class="chapter" data-level="18.2.2" data-path="anova.html"><a href="anova.html#value-2-interpretation"><i class="fa fa-check"></i><b>18.2.2</b> Value #2: Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="anova.html"><a href="anova.html#problems"><i class="fa fa-check"></i><b>18.3</b> Problems</a></li>
<li class="chapter" data-level="18.4" data-path="anova.html"><a href="anova.html#solutions"><i class="fa fa-check"></i><b>18.4</b> Solutions</a><ul>
<li class="chapter" data-level="18.4.1" data-path="anova.html"><a href="anova.html#solution-1-transformations"><i class="fa fa-check"></i><b>18.4.1</b> Solution 1: Transformations</a></li>
<li class="chapter" data-level="18.4.2" data-path="anova.html"><a href="anova.html#solution-2-link-functions"><i class="fa fa-check"></i><b>18.4.2</b> Solution 2: Link Functions</a></li>
<li class="chapter" data-level="18.4.3" data-path="anova.html"><a href="anova.html#solution-3-scientifically-backed-functions"><i class="fa fa-check"></i><b>18.4.3</b> Solution 3: Scientifically-backed functions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="glms-in-r.html"><a href="glms-in-r.html"><i class="fa fa-check"></i><b>19</b> GLM’s in R</a><ul>
<li class="chapter" data-level="19.0.1" data-path="glms-in-r.html"><a href="glms-in-r.html#broomaugment"><i class="fa fa-check"></i><b>19.0.1</b> <code>broom::augment()</code></a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="logistic-regression-paper-with-paul.html"><a href="logistic-regression-paper-with-paul.html"><i class="fa fa-check"></i><b>20</b> Logistic Regression paper with Paul</a><ul>
<li class="chapter" data-level="20.1" data-path="logistic-regression-paper-with-paul.html"><a href="logistic-regression-paper-with-paul.html#the-traditional-approach"><i class="fa fa-check"></i><b>20.1</b> The Traditional Approach</a><ul>
<li class="chapter" data-level="20.1.1" data-path="logistic-regression-paper-with-paul.html"><a href="logistic-regression-paper-with-paul.html#the-linear-probability-model"><i class="fa fa-check"></i><b>20.1.1</b> The Linear Probability Model</a></li>
<li class="chapter" data-level="20.1.2" data-path="logistic-regression-paper-with-paul.html"><a href="logistic-regression-paper-with-paul.html#the-logistic-model"><i class="fa fa-check"></i><b>20.1.2</b> The Logistic Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="robust-regression-in-r.html"><a href="robust-regression-in-r.html"><i class="fa fa-check"></i><b>21</b> Robust Regression in R</a><ul>
<li class="chapter" data-level="21.0.1" data-path="robust-regression-in-r.html"><a href="robust-regression-in-r.html#heavy-tailed-regression"><i class="fa fa-check"></i><b>21.0.1</b> Heavy Tailed Regression</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="from-linear-regression-to-mixed-effects-models.html"><a href="from-linear-regression-to-mixed-effects-models.html"><i class="fa fa-check"></i><b>22</b> From Linear Regression to Mixed Effects Models</a><ul>
<li class="chapter" data-level="22.1" data-path="from-linear-regression-to-mixed-effects-models.html"><a href="from-linear-regression-to-mixed-effects-models.html#motivation-for-lme"><i class="fa fa-check"></i><b>22.1</b> Motivation for LME</a></li>
<li class="chapter" data-level="22.2" data-path="from-linear-regression-to-mixed-effects-models.html"><a href="from-linear-regression-to-mixed-effects-models.html#definition"><i class="fa fa-check"></i><b>22.2</b> Definition</a></li>
<li class="chapter" data-level="22.3" data-path="from-linear-regression-to-mixed-effects-models.html"><a href="from-linear-regression-to-mixed-effects-models.html#r-tools-for-fitting"><i class="fa fa-check"></i><b>22.3</b> R Tools for Fitting</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="mixed-effects-models-in-r-tutorial.html"><a href="mixed-effects-models-in-r-tutorial.html"><i class="fa fa-check"></i><b>23</b> Mixed Effects Models in R: tutorial</a></li>
<li class="chapter" data-level="24" data-path="dsci-562-tutorial-missing-data.html"><a href="dsci-562-tutorial-missing-data.html"><i class="fa fa-check"></i><b>24</b> DSCI 562 Tutorial: Missing Data</a><ul>
<li class="chapter" data-level="24.1" data-path="dsci-562-tutorial-missing-data.html"><a href="dsci-562-tutorial-missing-data.html#mean-imputation"><i class="fa fa-check"></i><b>24.1</b> Mean Imputation</a></li>
<li class="chapter" data-level="24.2" data-path="dsci-562-tutorial-missing-data.html"><a href="dsci-562-tutorial-missing-data.html#multiple-imputation"><i class="fa fa-check"></i><b>24.2</b> Multiple Imputation</a><ul>
<li class="chapter" data-level="24.2.1" data-path="dsci-562-tutorial-missing-data.html"><a href="dsci-562-tutorial-missing-data.html#patterns"><i class="fa fa-check"></i><b>24.2.1</b> Patterns</a></li>
<li class="chapter" data-level="24.2.2" data-path="dsci-562-tutorial-missing-data.html"><a href="dsci-562-tutorial-missing-data.html#multiple-imputation-1"><i class="fa fa-check"></i><b>24.2.2</b> Multiple Imputation</a></li>
<li class="chapter" data-level="24.2.3" data-path="dsci-562-tutorial-missing-data.html"><a href="dsci-562-tutorial-missing-data.html#pooling"><i class="fa fa-check"></i><b>24.2.3</b> Pooling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="spatial.html"><a href="spatial.html"><i class="fa fa-check"></i><b>25</b> Spatial</a><ul>
<li class="chapter" data-level="25.1" data-path="spatial.html"><a href="spatial.html#a-model-for-river-rock-size"><i class="fa fa-check"></i><b>25.1</b> A Model for River Rock Size</a></li>
<li class="chapter" data-level="25.2" data-path="spatial.html"><a href="spatial.html#statistical-objectives"><i class="fa fa-check"></i><b>25.2</b> Statistical Objectives</a><ul>
<li class="chapter" data-level="25.2.1" data-path="spatial.html"><a href="spatial.html#preliminaries-variance-and-correlation"><i class="fa fa-check"></i><b>25.2.1</b> Preliminaries: Variance and Correlation</a></li>
</ul></li>
<li class="chapter" data-level="25.3" data-path="spatial.html"><a href="spatial.html#three-concepts"><i class="fa fa-check"></i><b>25.3</b> Three Concepts</a><ul>
<li class="chapter" data-level="25.3.1" data-path="spatial.html"><a href="spatial.html#error-variance-sigma_e2leftxright"><i class="fa fa-check"></i><b>25.3.1</b> Error Variance <span class="math inline">\(\sigma_{E}^{2}\left(x\right)\)</span></a></li>
<li class="chapter" data-level="25.3.2" data-path="spatial.html"><a href="spatial.html#mean-variance-sigma_m2"><i class="fa fa-check"></i><b>25.3.2</b> Mean Variance <span class="math inline">\(\sigma_{M}^{2}\)</span></a></li>
<li class="chapter" data-level="25.3.3" data-path="spatial.html"><a href="spatial.html#mean-correlation-rholeftdright"><i class="fa fa-check"></i><b>25.3.3</b> Mean Correlation <span class="math inline">\(\rho\left(d\right)\)</span></a></li>
</ul></li>
<li class="chapter" data-level="25.4" data-path="spatial.html"><a href="spatial.html#estimation-1"><i class="fa fa-check"></i><b>25.4</b> Estimation</a><ul>
<li class="chapter" data-level="25.4.1" data-path="spatial.html"><a href="spatial.html#constant-error-variance"><i class="fa fa-check"></i><b>25.4.1</b> Constant Error Variance</a></li>
<li class="chapter" data-level="25.4.2" data-path="spatial.html"><a href="spatial.html#non-constant-error-variance"><i class="fa fa-check"></i><b>25.4.2</b> Non-Constant Error Variance</a></li>
</ul></li>
<li class="chapter" data-level="25.5" data-path="spatial.html"><a href="spatial.html#statistical-objective-1-downstream-fining-curve"><i class="fa fa-check"></i><b>25.5</b> Statistical Objective 1: Downstream Fining Curve</a><ul>
<li class="chapter" data-level="25.5.1" data-path="spatial.html"><a href="spatial.html#regression-form"><i class="fa fa-check"></i><b>25.5.1</b> Regression Form</a></li>
</ul></li>
<li class="chapter" data-level="25.6" data-path="spatial.html"><a href="spatial.html#statistical-objective-2-river-profile"><i class="fa fa-check"></i><b>25.6</b> Statistical Objective 2: River Profile</a><ul>
<li class="chapter" data-level="25.6.1" data-path="spatial.html"><a href="spatial.html#simple-kriging"><i class="fa fa-check"></i><b>25.6.1</b> Simple Kriging</a></li>
<li class="chapter" data-level="25.6.2" data-path="spatial.html"><a href="spatial.html#universal-kriging"><i class="fa fa-check"></i><b>25.6.2</b> Universal Kriging</a></li>
<li class="chapter" data-level="25.6.3" data-path="spatial.html"><a href="spatial.html#kriging-under-non-constant-error-variance"><i class="fa fa-check"></i><b>25.6.3</b> Kriging under Non-Constant Error Variance</a></li>
</ul></li>
<li class="chapter" data-level="25.7" data-path="spatial.html"><a href="spatial.html#confidence-intervals-of-the-river-profile"><i class="fa fa-check"></i><b>25.7</b> Confidence Intervals of the River Profile</a></li>
</ul></li>
<li class="chapter" data-level="26" data-path="timeseries-in-base-r.html"><a href="timeseries-in-base-r.html"><i class="fa fa-check"></i><b>26</b> Timeseries in (base) R</a></li>
<li class="divider"></li>
<li><a href="https://github.com/vincenzocoia/Interpreting-Regression" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interpreting Regression</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="quantile-regression" class="section level1">
<h1><span class="header-section-number">Chapter 6</span> Quantile Regression</h1>
<p><strong>Caution: in a highly developmental stage! See Section <a href="index.html#caution">1.1</a>.</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">suppressPackageStartupMessages</span>(<span class="kw">library</span>(tidyverse))
<span class="kw">suppressPackageStartupMessages</span>(<span class="kw">library</span>(Lahman))</code></pre></div>
<p>It’s common to “default” to using the mean to make decisions. But, the mean is not always appropriate (I wrote a <a href="https://vincenzocoia.github.io/20180218-mean/">blog post</a> about this):</p>
<ul>
<li>Sometimes it makes sense to relate the outcome to a coin toss.
<ul>
<li>For example, find an amount for which next month’s expenditures will either exceed or be under with a 50% chance.</li>
</ul></li>
<li>Sometimes a conservative/liberal estimate is wanted.
<ul>
<li>For example, a bus company wants conservative estimates so that <em>most</em> busses fall within the estimated travel time.</li>
</ul></li>
</ul>
<p>In these cases, we care about <em>quantiles</em>, not the mean. Estimating them is called <strong>quantile regression</strong> (as opposed to <strong>mean regression</strong>).</p>
<p>Recall what quantiles are: the <span class="math inline">\(\tau\)</span>-quantile (for <span class="math inline">\(\tau\)</span> between 0 and 1) is the number that will be exceeded by the outcome with a <span class="math inline">\((1-\tau)\)</span> chance. In other words, there is a probability of <span class="math inline">\(\tau\)</span> that the outcome will be <em>below</em> the <span class="math inline">\(\tau\)</span>-quantile.</p>
<p><span class="math inline">\(\tau\)</span> is referred to as the <em>quantile level</em>, or sometimes the <em>quantile index</em>.</p>
<p>For example, a bus company might want to predict the 0.8-quantile of transit time – 80% of busses will get to their destination within that time.</p>
<div id="what-is-the-mean-anyway" class="section level2">
<h2><span class="header-section-number">6.1</span> What is the mean, anyway?</h2>
<p>Imagine trying to predict your total expenses for the next two years. You have monthly expenses listed for the past 12 months. What’s one simple way of making your prediction? Calculate the average expense from the past 12 months, and multiply that by 24.</p>
<p>In general, a mean (or expected value) can be interpreted as the <em>long-run average</em>. However, the mean tends to be interpreted as a <em>measure of central tendency</em>, which has a more nebulous interpretation as a “typical” outcome, or an outcome for which most of the data will be “nearest”.</p>
</div>
<div id="linear-quantile-regression" class="section level2">
<h2><span class="header-section-number">6.2</span> Linear Quantile Regression</h2>
<p>The idea here is to model <span class="math display">\[Q(\tau)=\beta_0(\tau) + \beta_1(\tau) X_1 + \cdots + \beta_p(\tau) X_p,\]</span> where <span class="math inline">\(Q(\tau)\)</span> is the <span class="math inline">\(\tau\)</span>-quantile. In other words, <strong>each quantile level gets its own line</strong>, and are each fit independently of each other.</p>
<p>Here are the 0.25-, 0.5-, and 0.75-quantile regression lines for the baseball data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(dat, <span class="kw">aes</span>(hits, runs)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="fl">0.1</span>, <span class="dt">colour=</span><span class="st">&quot;orange&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_quantile</span>(<span class="dt">colour=</span><span class="st">&quot;black&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;Number of Hits (X)&quot;</span>,
         <span class="dt">y=</span><span class="st">&quot;Number of Runs (Y)&quot;</span>)</code></pre></div>
<pre><code>## Loading required package: SparseM</code></pre>
<pre><code>## 
## Attaching package: &#39;SparseM&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:base&#39;:
## 
##     backsolve</code></pre>
<pre><code>## Smoothing formula not specified. Using: y ~ x</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
<p>I did this easily with <code>ggplot2</code>, just by adding a layer <code>geom_quantile</code> to my scatterplot, specifying the quantile levels with the <code>quantiles=</code> argument. We could also use the function <code>rq</code> in the <code>quantreg</code> package in R:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">(fit_rq &lt;-<span class="st"> </span><span class="kw">rq</span>(runs <span class="op">~</span><span class="st"> </span>hits, <span class="dt">data=</span>dat, <span class="dt">tau=</span><span class="kw">c</span>(<span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>)))</code></pre></div>
<pre><code>## Call:
## rq(formula = runs ~ hits, tau = c(0.25, 0.5, 0.75), data = dat)
## 
## Coefficients:
##                tau= 0.25 tau= 0.50  tau= 0.75
## (Intercept) -118.8297872 8.2101818 64.0347349
## hits           0.5531915 0.4923636  0.4908592
## 
## Degrees of freedom: 2835 total; 2833 residual</code></pre>
<p>If we were to again focus on the two teams (one with 1000 hits, and one with 1500 hits), we have (by evaluating the above three lines):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">predict</span>(fit_rq, <span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">hits=</span><span class="kw">c</span>(<span class="dv">1000</span>, <span class="dv">1500</span>)))</code></pre></div>
<pre><code>##   tau= 0.25 tau= 0.50 tau= 0.75
## 1  434.3617  500.5738  554.8940
## 2  710.9574  746.7556  800.3236</code></pre>
<p>So, we could say that the team with 1000 hits:</p>
<ul>
<li>is estimated to have a 50% chance to have between 434 and 555 runs;</li>
<li>has a 25% chance of achieving over 555 runs;</li>
<li>has a 25% chance of getting less than 434 runs;</li>
<li>would typically get 501 runs (median);</li>
</ul>
<p>amongst other things.</p>
</div>
<div id="exercise-1" class="section level2">
<h2><span class="header-section-number">6.3</span> Exercise</h2>
<ul>
<li>Get a 95% prediction interval using linear quantile regression, with Y=<code>R</code> (number of runs), X=<code>H</code> (number of hits), when X=1500.</li>
<li>What about a 95% PI using kNN, going back to the earlier example we did?</li>
</ul>
</div>
<div id="problem-crossing-quantiles" class="section level2">
<h2><span class="header-section-number">6.4</span> Problem: Crossing quantiles</h2>
<p>Because each quantile is allowed to have its own line, some of these lines might cross, giving an <strong>invalid result</strong>. Here is an example with the <code>iris</code> data set, fitting the 0.2- and 0.3-quantiles:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(iris, <span class="kw">aes</span>(Sepal.Length, Sepal.Width)) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="dt">alpha=</span><span class="fl">0.25</span>, <span class="dt">colour=</span><span class="st">&quot;orange&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_quantile</span>(<span class="kw">aes</span>(<span class="dt">colour=</span><span class="st">&quot;0.2&quot;</span>), <span class="dt">quantiles=</span><span class="fl">0.2</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_quantile</span>(<span class="kw">aes</span>(<span class="dt">colour=</span><span class="st">&quot;0.3&quot;</span>), <span class="dt">quantiles=</span><span class="fl">0.3</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">scale_colour_discrete</span>(<span class="st">&quot;Quantile</span><span class="ch">\n</span><span class="st">Level&quot;</span>) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">x=</span><span class="st">&quot;Sepal Length&quot;</span>,
         <span class="dt">y=</span><span class="st">&quot;Sepal Width&quot;</span>)</code></pre></div>
<pre><code>## Smoothing formula not specified. Using: y ~ x
## Smoothing formula not specified. Using: y ~ x</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">fit_iris &lt;-<span class="st"> </span><span class="kw">rq</span>(Sepal.Width <span class="op">~</span><span class="st"> </span>Sepal.Length, <span class="dt">data=</span>iris, <span class="dt">tau=</span><span class="dv">2</span><span class="op">:</span><span class="dv">3</span><span class="op">/</span><span class="dv">10</span>)
b &lt;-<span class="st"> </span><span class="kw">coef</span>(fit_iris)
at8 &lt;-<span class="st"> </span><span class="kw">round</span>(<span class="kw">predict</span>(fit_iris, <span class="dt">newdata=</span><span class="kw">data.frame</span>(<span class="dt">Sepal.Length=</span><span class="dv">8</span>)), <span class="dv">2</span>)</code></pre></div>
<p>Quantile estimates of Sepal Width for plants with Sepal Length less than <code>7.3</code> are valid, but otherwise, are not. For example, for plants with a Sepal Length of 8, this model predicts 30% of such plants to have a Sepal Width of less than <code>2.75</code>, but only 20% of such plants should have Sepal Width less than <code>2.82</code>. This is an illogical statement.</p>
<p>There have been several “adjustments” proposed to ensure that this doesn’t happen (see below), but ultimately, this suggests an inadequacy in the model assumptions. Luckily, this usually only happens at extreme values of the predictor space, and/or for large quantile levels, so is usually not a problem.</p>
<ul>
<li>Bondell HD, Reich BJ, Wang H. Noncrossing quantile regression curve estimation. Biometrika. 2010;97(4):825-838.</li>
<li>Dette H, Volgushev S. Non-crossing non-parametric estimates of quantile curves. J R Stat Soc Ser B Stat Methodol. 2008;70(3):609-627.</li>
<li>Tokdar ST, Kadane JB. Simultaneous linear quantile regression: a semiparametric Bayesian approach. Bayesian Anal. 2011;6(4):1-22.</li>
</ul>
</div>
<div id="problem-upper-quantiles" class="section level2">
<h2><span class="header-section-number">6.5</span> Problem: Upper quantiles</h2>
<p>Estimates of higher quantiles usually become worse for large/small values of <span class="math inline">\(\tau\)</span>. This is especially true when data are heavy-tailed.</p>
<p>Here is a histogram of 100 observations generated from a Student’s <em>t</em>(1) distribution (it’s heavy-tailed):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">4</span>)
y &lt;-<span class="st"> </span><span class="kw">rt</span>(<span class="dv">100</span>, <span class="dt">df=</span><span class="dv">1</span>)
<span class="kw">qplot</span>(y) <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()</code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>Here are estimates of high and low quantiles, compared to the actual. You can see the discrepency grows quickly. <strong>Extreme-low quantiles are too high</strong>, whereas <strong>extreme-high quantiles are too low</strong>.</p>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-25-1.png" width="768" /></p>
<p>As a rule of thumb, it’s best to stay below <span class="math inline">\(\tau=0.95\)</span> or above <span class="math inline">\(\tau=0.05\)</span>. If you really want estimates of these extreme quantiles, you’ll need to turn to <strong>Extreme Value Theory</strong> to make an assumption on the tail of the distribution of the data. One common approach is to fit a generalized Pareto distribution to the upper portion of the data, after which you can extract high quantiles.</p>
</div>
<div id="evaluating-model-goodness-1" class="section level2">
<h2><span class="header-section-number">6.6</span> Evaluating Model Goodness</h2>
<p>The question here is: if we have two or more models that predicts the <span class="math inline">\(\tau\)</span>-quantile, which model is best? We’ll need some way to score different models to do things such as:</p>
<ul>
<li>Choose which predictors to include in a model;</li>
<li>Choose optimal hyperparameters;</li>
<li>Estimate parameters in a quantile regression model.</li>
</ul>
<p>**<strong>NOTE</strong>**: <strong>Mean Squared Error is not appropriate here!!</strong> This is very important to remember.</p>
<p>The reason is technical – the MSE is not a <em>proper scoring rule</em> for quantiles. In other words, the MSE does not elicit an honest prediction.</p>
<p>If we’re predicting the <strong>median</strong>, then the <em>mean absolute error</em> works. This is like the MSE, but instead of <em>squaring</em> the errors, we take the <em>absolute value</em>.</p>
<p>In general, a “correct” scoring rule for the <span class="math inline">\(\tau\)</span>-quantile is as follows: <span class="math display">\[ S = \sum_{i=1}^{n} \rho_{\tau}(Y_i - \hat{Q}_i(\tau)), \]</span> where <span class="math inline">\(Y_i\)</span> for <span class="math inline">\(i=1,\ldots,n\)</span> is the response data, <span class="math inline">\(\hat{Q}_i(\tau)\)</span> are the <span class="math inline">\(\tau\)</span>-quantile estimates, and <span class="math inline">\(\rho_{\tau}\)</span> is the <strong>check function</strong> (also known as the <em>absolute asymmetric deviation function</em> or <em>tick function</em>), given by <span class="math display">\[ \rho_{\tau}(s) = (\tau - I(s&lt;0))s \]</span> for real <span class="math inline">\(s\)</span>. This scoring rule is <strong>negatively oriented</strong>, meaning the lower the score, the better. It cannot be below 0.</p>
<p>Here is a plot of various check functions. Notice that, when <span class="math inline">\(\tau=0.5\)</span> (corresponding to the median), this is proportional to the absolute value:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">base &lt;-<span class="st"> </span><span class="kw">ggplot</span>(<span class="kw">data.frame</span>(<span class="dt">x=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">2</span>,<span class="dv">2</span>)), <span class="kw">aes</span>(x)) <span class="op">+</span><span class="st"> </span>
<span class="st">    </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">labs</span>(<span class="dt">y=</span><span class="kw">expression</span>(rho)) <span class="op">+</span>
<span class="st">    </span><span class="kw">theme</span>(<span class="dt">axis.title.y=</span><span class="kw">element_text</span>(<span class="dt">angle=</span><span class="dv">0</span>, <span class="dt">vjust=</span><span class="fl">0.5</span>)) <span class="op">+</span>
<span class="st">    </span><span class="kw">ylim</span>(<span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">1.5</span>))
rho &lt;-<span class="st"> </span><span class="cf">function</span>(tau) <span class="cf">function</span>(x) (tau <span class="op">-</span><span class="st"> </span>(x<span class="op">&lt;</span><span class="dv">0</span>))<span class="op">*</span>x
cowplot<span class="op">::</span><span class="kw">plot_grid</span>(
    base <span class="op">+</span><span class="st"> </span><span class="kw">stat_function</span>(<span class="dt">fun=</span><span class="kw">rho</span>(<span class="fl">0.2</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">        </span><span class="kw">ggtitle</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(tau, <span class="st">&quot;=0.2&quot;</span>))),
    base <span class="op">+</span><span class="st"> </span><span class="kw">stat_function</span>(<span class="dt">fun=</span><span class="kw">rho</span>(<span class="fl">0.5</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">        </span><span class="kw">ggtitle</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(tau, <span class="st">&quot;=0.5&quot;</span>))),
    base <span class="op">+</span><span class="st"> </span><span class="kw">stat_function</span>(<span class="dt">fun=</span><span class="kw">rho</span>(<span class="fl">0.8</span>)) <span class="op">+</span><span class="st"> </span>
<span class="st">        </span><span class="kw">ggtitle</span>(<span class="kw">expression</span>(<span class="kw">paste</span>(tau, <span class="st">&quot;=0.8&quot;</span>))),
    <span class="dt">ncol=</span><span class="dv">3</span>
)</code></pre></div>
<pre><code>## Warning: Removed 4 rows containing missing values (geom_path).

## Warning: Removed 4 rows containing missing values (geom_path).</code></pre>
<p><img src="bookdown-demo_files/figure-html/unnamed-chunk-26-1.png" width="768" /></p>
<p>For quantile regression <strong>estimation</strong>, we minimize the sum of scores instead of the sum of squared residuals, as in the usual (mean) linear regression.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probabilistic-forecasting.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="introduction-to-machine-learning.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/vincenzocoia/Interpreting-Regression/edit/master/033-quantile_regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
