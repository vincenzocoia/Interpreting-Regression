# Simple Linear Regression

**Caution: in a highly developmental stage! See Section  \@ref(caution).**

(From lab2, DSCI 561, 2018-2019)

When a predictor is categorical, it's easy to estimate the mean given a certain predictor value (i.e., given the category): just take the sample average of the data in that group.

Now let's consider a numeric predictor. Using the iris dataset again with sepal width as a response, use sepal length as the predictor. Here is a scatterplot of the data:

```
(p_numeric_x <- ggplot(iris, aes(Sepal.Length, Sepal.Width)) +
    geom_point(alpha=0.25) +
    theme_bw() +
    labs(x = "Sepal Length",
         y = "Sepal Width"))
```

How can we estimate the mean sepal width ($Y$) for any given sepal length ($X$)? Say we want the mean of $Y$ at $X=x$ (for some pre-decided $x$). Last week in DSCI 571 Lab 2 Exercise 5, you saw one way of estimating this: calculate the mean sepal width ($Y$) using only the $k$ plants having sepal lengths ($X$ values) closest to $x$ (the sepal length you're interested in).

Methods like this are very powerful estimation methods, but there's merit in assuming the mean is linear in $x$: $$E(Y \mid X=x) = \beta_0 + \beta_1 x,$$ for some numbers $\beta_0$ and $\beta_1$ (to be estimated).

How do we estimate $\beta_0$ and $\beta_1$? In other words, how do we pick an acceptable line? Since we want the line to represent the mean, choose the line that minimizes the sum of squared errors! Remember, this is another way of writing the sample average in the univariate case, and now we can generalize the univariate mean to the regression setting in this way.

Is it possible to find a line that has a smaller sum of squared errors than what you found in Exercise 3.3? Why or why not? Is it possible to find a line that has a smaller sum of absolute errors (i.e., the absolute value of the errors)? Elaborate.

## Model Specification

You might see linear regression models specified in different ways.

In this exercise, we're still working with sepal length as the only predictor of sepal width.

Denote $\beta_0$ as the true intercept of the regression line, and $\beta_1$ as the true slope. As we've said, we're assuming that the mean of $Y$ is linear in the predictor: $$E(Y \mid X=x) = \beta_0 + \beta_1 x.$$ There are other ways to write this model; i.e., different ways of saying the same thing (not to be confused with different parameterizations). We'll explore this here.

4.1
rubric={reasoning:3}

One way to write this model is to emphasize that this model holds for every single observation, instead of for a generic $Y$. Denote $Y_i$ as the random variable corresponding to the $i$'th observation of the response, and $x_i$ the corresponding observed value of the predictor. Let $n$ be the sample size.

Your task: specify what goes in the $?$ in the following equation:

$$E(Y_i | X_i = x_i) = \text{ ?}, \text{ for each } i=1,\ldots,n.$$
YOUR ANSWER HERE

4.2
rubric={reasoning:3}

We could also specify how $Y_i$ itself was supposedly calculated. Your task: specify what goes in the $?$ in the following equation.

$$Y_i = \text{ ?}, \text{ for each } i=1,\ldots,n.$$
Hint: you'll have to introduce a variable. Be sure to specify any assumptions about this variable so that your equation is equivalent to the one in Exercise 4.1 -- this means not putting more assumptions than are necessary, too!

YOUR ANSWER HERE

4.3
rubric={reasoning:3}

Instead of having to say "for each $i=1,\ldots,n$", we could just write out each of the $n$ equations. It's actually convenient to do so, but expressed as one equation by using matrix algebra.

We'll use bold-face to denote vectors. Denote $\boldsymbol{Y}$ as the vector containing $Y_1,\ldots,Y_n$ (in that order), and similarly for $\boldsymbol{X}$ and $\boldsymbol{x}$. Denote $\boldsymbol{\beta}$ as the vector containing $\beta_0$ and $\beta_1$ (in that order). Then, the same equation becomes: $$E(\boldsymbol{Y} \mid \boldsymbol{X} = \boldsymbol{x}) = \text{? }\boldsymbol{\beta}, $$ where "?" is an $n \times 2$ matrix.

Your task: specify the matrix indicated by "?" in the above equation. It's probably most convenient to describe what each column contains. Each column is worth approx. 50% of your grade for this question.

YOUR ANSWER HERE
